### 2024-05-02 (목) 기능구현
# 프론트엔드
- 사용자 기기의 카메라를 통해 얼굴을 촬영하고, 해당 얼굴에 대한 감정을 분석해야함.
- 위 기능을 구현하기 위한 페이지를 만듦
- 구현 목표 : ReactNative에 카메라 가져오기 + Overlay로 디자인하기

### Expo Camera Library
- https://docs.expo.dev/versions/latest/sdk/camera/
- 위 링크는 Expo에서 공식적으로 지원하는 Camera import library
- 예제를 따라가보며 구현했다.  
- ![image](https://github.com/ChaeDoll/TIL/assets/108540812/428044b8-f3e8-48ad-a15e-35981af13745)
- 사용자의 카메라 권한을 먼저 승인받아야 Camera를 사용할 수 있다. 따라서 Camera 클래스의 useCameraPermissions() 훅을 통해 사용자에게 권한을 승인받는 requestPermission, 그리고 권한여부를 나타내는 permission을 가져올 수 있다.
- 먼저 permission 객체가 가져와졌는지 1차적으로 확인하고, 두번째로 permission객에서 아직 권한이 부여되지 않았다면 (!permission.granted) 권한을 승인받기 위한 창이 뜨게 만들었다.
- ![image](https://github.com/ChaeDoll/TIL/assets/108540812/6c1f1d2d-d757-4aef-9525-6ec5f0dd0d15)
- 권한이 부여됐다면 Camera 태그를 통해 카메라를 불러오고, type을 CameraType.front로 설정하여 전면카메라로 설정한다. (얼굴인식을 위해 전면카메라)

### 구현
- 우리가 원하는 Screen의 형태는 아래와 같다. (Figma 참고)
- ![image](https://github.com/ChaeDoll/TIL/assets/108540812/22987038-d73d-4997-b135-9728d5596e39)
- 여기서 카메라 위 아래로 Overlay가 존재해야한다. 텍스트 혹은 버튼이 존재해야하는데, 이를 position:absolute로 설정하여 카메라 위 아래에 Overlay로 덮이도록 설정하였다.
- 카메라가 초기 설정으로 굉장히 상하 비율이 길다.. 이를 조정할 필요가 있었기에 heightPercentToDP 라이브러리를 통해 기존보다 63%의 크기로 설정하였다. 아래 사진은 초기 모습
-  <img src="https://github.com/ChaeDoll/TIL/assets/108540812/188a356f-52f4-4cac-9c9c-5a7f77d2e6a9" width="20%">
- 코드를 수정하여 아래와 같은 결과를 얻어낼 수 있었다.
- <img src="https://github.com/ChaeDoll/TIL/assets/108540812/aba5d4fa-ea69-4f4e-bd4f-7ddad2bd2562" width="80%"> <img src="https://github.com/ChaeDoll/TIL/assets/108540812/d8d8474b-c0d1-46ad-a23d-835e4dd48ddf" width="15%">
- 원래 피그마에서 구현하고자 한 목표에 가까워졌다.
  
### 계획
- 이제 카메라를 촬영하고, 촬영한 사진을 데이터화 시켜서 ai얼굴인식 모델로 전송해야한다. (모델 구현을 최민석 학생이 구현하면 내가 api를 통해 전달)
- 또한 결과를 화면에 띄우고, 해당 기분이 맞는지 아닌지 '아니에요 맞아요' 버튼을 통해 재시도 혹은 다음화면으로 넘어갈 수 있는 기능을 구현한다.
