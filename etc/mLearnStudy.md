# 기계학습 중간고사 정리  
## 1주차  
### 기계학습이란..  
기계학습은 Machine Learning이라고도 불린다.  
기계학습은 인공지능 기술의 기초 분야로서, 매우중요한 역할을 한다.  
설명에 앞서, 기계학습 강의에서는 데이터가 중요함, 어떤 모델을 사용하는지가 중요함, 기계학습방법 과정 이 중에서 모델 선택과 학습과정에 대한 설명이 주가 될 것이다.  

과거 10년전부터 각광받은 '인공지능'이라 불리던 것은 사실상 머신러닝이다.  
컴퓨터가 스스로 학습하여 성능을 향상시키는 기술방법으로, 머신러닝 중에서도 인간의 뉴런과 비슷한 방식으로 정보를 처리하는 기술을 딥러닝이라고 부른다.  
인공지능 안에 머신러닝이 있고, 머신러닝 안에 딥러닝이 있다.  
우리는 여러 공부를 하거나, 자전거를 타거나 등등 여러 실패를 거듭하며 오차를 줄여나가며 원하는 목표로 다가가는 학습을 한다.  
기계학습의 기초 원리는 이러한 사람의 학습에서 비롯되었다.  

인공지능은 컴퓨터에 대한 기대감으로 인해 탄생되었다.  
컴퓨터는 매우 뛰어난 능력을 갖고 사람이 어려워하는 일들을 쉽게 해내었는데, 그로 인하여 인간이 하기 쉬운 일도 잘 하지 않을까 하는 기대감이 있었다.  
그리하여 사람이 하는 일을 수행할 수 있는 인공지능이라는 분야가 등장했다.  
초창기엔 지식기반으로 분류하는 방식이 주였다.  
하지만 지식기반으로 하면 오류가 발생하기 쉽다.  
모든 장면을 인식할 때 우리가 왜 그렇게 인식하는지를 설명하려면 매우 어려울 것임.  

그래서, 사람의 지식을 기반으로 학습을 시키는 것이 아닌, 주도권을 인공지능에게 주어 데이터 중심으로 접근하도록 전환하기 시작했다.  
이것이 기계학습 방식인 데이터중심 접근방식이다.  

데이터가 들어왔을 때, 그 결과를 예측하기 위해서 훈련이 필요하고 훈련집합들로 훈련된 학습을 통해 새로운 데이터의 값을 예측한다.  
훈련집합은 가로축은 특징, 세로축은 목표치이다.(X와 Y)  
특징들과 목표치로 이루어진 훈련집합들은 얼핏 보면 직선을이루기에 기계학습의 모델로 직선을 택하는 편이다.  
직선이기에 모델의 수식은 y=wx+b의 형태로 w와 b 두개의 매개변수로 이루어진다.(1차식, 0차식)  

기계학습은 최적의 매개변수를 찾는 작업이다. 가장 정확한 예측을 위해서.  
처음엔 최적값을 모르기에 임의값에서 시작. 점점 성능개선되며 최적에도달  

학습을 하고 학습을 마치면 예측에 사용한다.  
궁극적인 목표는 훈련집합에 없는 새로운 샘플에 대한 오류를 최소화 하는 것이며,  
이런 성능을 <b>일반화능력</b>이라고 부른다.  

사람과 기계는 학습방법이 차이가 있다.  
- 학습 과정 : 사람은 능동적, 기계는 수동적  
- 데이터 형식 : 자연에 존재하는 그대로, 일정 형식에 맞추어 사람이 준비  
- 동시 학업 가능 과업 수 : 자연스럽게 여러 과업 학습, 하나의 과업만 가능  
- 학습 원리에 대한 지식 : 매우 제한적으로 알려짐, 모든 과정이 다 밝혀짐  
- 수학 의존도 : 매우 낮음, 매우 높음  
- 성능 평가 : 경우에 따라 객관적or주관적, 객관적(예를들면 정확률 99.8%)  
- 역사 : 수백만 년, 60년 가량  

### 특징공간  
특징이 x고 목푯값이 y라고 했는데, 이를 활용하여 x축 y축을 통해 특징공간을 나타내기도 한다.  
x가 d개라면 d차원 특징공간이라고 부를 수 있음.  
d차원 데이터는 X=(x1,x2,...,xd)^T 로 특징벡터를 표기할 수 있다.  
직선모델의 경우 매개변수의 수는 d+1개이고, 목푯값 y기준으로는 y=w1x1+w2x2+...+wdxd+b 로 나타낼 수 있다.  
2차 곡선모델 사용하면 매개변수수가 d^2+d+1개라서 매개변수 수가 크게 증가한다.  

### 데이터  
과학기술의 발전은 '데이터 수집->모델 정립->예측->데이터 수집...' 이렇다.  
기계 학습의 경우에는 수학공식을 통해 분류를 표현하기는 불가능하다.  
따라서 자동으로 모델을 찾아내는 과정이 필요하다.  

데이터가 어떻게 만들어지는지(예측값이 어떤 방식으로..) 완전히 아는 인위적 상황을 '데이터 생성과정을 완전히 알고 있다'라고 말한다.  
x를 알면 y를 예측할 수 있고 x의 발생확률 P(x)도 정확히 알 수 있다.  
하지만 실제 기계학습은 데이터의 생성과정(결과도출방법)을 알 수가 없다.  
그저 훈련집합 X, Y를 사용해 예측모델이나 생성모델을 근사 추정할 수 있을 뿐이다.  

데이터베이스가 중요한게, 위 같은 상황에서 훈련집합이 많아야 원하는 근사추정이 가능해질텐데,  
데이터베이스 품질이 좋다면 주어진 응용에 맞는 충분히 다양한 데이터를 충분한 양만큼 충전해서 추정 정확도가 높아진다.(<b>주어진 응용 환경을 잘 살피고 그에 맞는 데이터베이스 확보 아주 중요</b>)  
3가지 공개 데이터베이스는 Iris(꽃), MNIST(숫자), ImageNet(영상)  

### 데이터베이스  
데이터베이스는 솔직히 왜소한 크기이다.  
28*28의 흑백 픽셀은 2^784가지의 경우가 나오지만 정작 MNIST샘플은 6만개밖에 안됨.  
이런 작은 데이터베이스로 높은 성능을 달성할 수 있는 이유는,  
막상 큰 공간에서 실제 데이터가 쓰이는 곳은 매우 작은 부분임.  
또한 <b>매니폴드 가정</b>을 통해 샘플들이 고차원에 있어도 일정한 규칙에 따라 변화한다 보아, 샘플들을 아우르는 저차원공간이 존재할 것이라는 가정  

### 데이터 가시화..  
4차원 이상 초공간은한번에 가시화 안되는데.. 2개씩 조합해서 여러개의 그래프를 그린다.  

### 모델 선택  
기계학습에서 모델을 선택할 때 과소적합이나 과잉적합에 주의해야한다.  
말 그대로 과소적합은 너무 오차가 많은 상황으로, 모델의 용량이 '작을 때' 많이 발생한다.  
ex) 1차 모델을 사용했더니 너무 오차가 큼  
따라서 오차를 줄이기위해 2차 이상의 다항식 곡선을 사용한 비선형 모델을 사용하는 것이 대안이 된다.  
1차 모델에 비해 오차가 크게 감소한다는 장점.  
하지만 너무 큰 차수의 다항식 곡선을 택하면 오히려 너무 과잉적합하다는 문제가 생긴다.  
ex) 12차 다항식 곡선을 모델로 사용했더니 훈련집합에는 잘 맞지만 '새로운' 데이터를 예측하기엔 오히려 오차가 생겼다.  
용량이 너무 크면 학습 시에 잡음까지 담아버리는데, 이 때문에 오차가 생기게 된 것이다.  

요약하면, 과소적합하지도 않고 과잉적합하지도 않는 적절한 용량의 모델을 선택하는 작업이 필요하다.  
높은 일반화 능력을 갖기 위해서 적절한 타협점이 필요한데, 보통 3~4차가 좋은 일반화 능력을 보이기도...  

모델을 선택하게 되면, 바이어스와 분산이 나타나는데 낮은차 다항식은 바이어스가 큰 대신 비슷한 모델을 얻는다는 점에서 낮은 분산을 갖는다. (높은 바이어스, 낮은 분산)  
하지만 고차다항식은 오차가 작은 점에서 바이어스가 작은 대신 크게 다른 모델을 얻기에 높은 분산을 보인다. (낮은 바이어스, 높은 분산)  
이 둘은 서로 역관계이다.  
우리는 낮은 바이어스와 낮은 분산을 갖는 예측기를 필요로한다.  
<b>바이어스를 최소로 희생하도록 유지하며 분산을 최대한 낮추는 전략이 필요하다</b>  

모델은 종류가 다양하다. 1차~12차 다항식이 SVM(Support Vector Machine), 트리분류기, 신경망, 강화학습 등 방법으로 선택될 수 있다.  
모델 종류도 많은데 각각 장단점이 있기때문에 문제 상황마다 더 좋은 모델이 있을 것이다.  

현실에서는 '경험'을 사용하여 큰 틀을 먼저 택한다.  
이후 모델 선택 알고리즘으로 세부 모델을 선택하는 전략을 사용한다.  
현대 기계학습에서는 용량이 큰 모델을 택하고, 선택한 모델이 정상에서 벗어나지 않도록 규제(regularization)하는 기법을 적용한다.  
ex) 12차 다항식 택하고 적절한 규제 적용  

### 규제란...  
<b>데이터확대</b>  
일단 데이터를 많이 확대하면 할수록(훈련집합 많아짐) 일반화 능력이 향상된다.  
데이터수집에 많은 비용이 들기에, 이를 절감하기 위해 훈련집합의 데이터 샘플들을 변형시키며 인위적으로 데이터를 확대할 수 있다.  
(부류 소속이 변하지 않는 선에서 약간 회전하거나 늘리거나 찌부하거나)  
이 방법을 쓰면 큰 용량에서 사용할 수 있을 만큼 많은 훈련집합의 크기를 얻어낼 수 있다.  
<b>가중치 감쇠</b>  
가중치를 작게 조절하는 방식을 사용하여 마치 낮은차수의 곡선처럼 형태를 만드는 것이다.  
점차 개선된 목적함수를 사용하며 가중치를 작게 조절하는 규제기법이다.  

### 지도 방식에 따른 유형  
정리를 해보면 이와 같다.  
- 기계학습  
 - 지도학습 : 정답이 존재  
  - 회귀 : 데이터를 잘 설명하는 선을 찾아 미래값 예측  
  - 분류 : 주어진 데이터가 어떤 클래스에 속할지 예측  
 - 비지도학습 : 정답이 존재하지 않음  
  - 클러스터링 : 그룹에 대한 정보없이 유사한 특징을 가진 개체끼리 군집화  
  - 차형축소 : 고차원 데이터의 차원을 축소해서 데이터를 더 잘 설명가능하게 함  
 - 강화학습 : 보상과 벌점  

### 그 중에서...  
<b>지도학습</b>  
정답이 주어진 상태에서 학습하는 알고리즘인데,  
훈련 데이터로부터 하나의 함수를 유추하고 종류로는 회귀분석과 분류가 있다.  
<b>비지도학습</b>  
정답이 주어지지 않는 상태에서 데이터의 특성을 학습하는 알고리즘이다.  
데이터가 어떻게 구성되었는지 알아내는 문제를 해결  
지도학습, 강화학습과는 달리 입력값에 대한 목표치(y)가 없다  
군집화와 연관규칙이 여기에 속한다.  
<b>강화학습</b>  
보상이나 벌칙을 통해 여러번 시행착오를 거치며 스스로 학습하는 방법이다.  
분류할 데이터나 정답은 없고 단지 행동에 보상과 벌칙을 통해 학습한다.  
보상을 최대한 많이 얻도록 하는 행동을 유도하는 학습을 진행한다.  
아이가 일어나서 걷는 방식이나 알파고와 같은 방식이 그 예시이다.  


## 2주차 - 기계학습과 Python, 수학  
### Python?  
파이썬이 데이터 과학 분야에서는 표준 프로그래밍 언어이다.  
다양한 라이브러리가 존재하여 데이터를 적재하거나 시각화, 통계, 자연어처리, 이미지처리 등이 편리하다.  
터미널이나 주피터노트북 같은 도구로 대화하듯 프로그래밍이 가능하다.  
머신러닝과 데이터분석은 데이터 주도 분석이라는 점에서 반복작업이 근본적으로 필요로하고,  
이러한 반복작업을 쉽고 빠르게 처리할 도구가 필요하다.  
복잡한 GUI나 웹서비스 만들수있고 기존시스템과 통합하기도 좋아서 쓴다.  
사이킷런이라는 오픈소스. 사이킷런은 NumPy와 SciPy를사용. 그래프 그리기 위해 matplotlib를 대화식으로는 Ipython과 주피터노트북 필요  
필요한 패키지 모아놓은 파이썬 배포판 설치하는것 권장  

### 기계학습 위해 Python에 쓰는 라이브러리들  
- 주피터노트북 : 프로그램 코드를 브라우저에서 실행해주는 대화식 환경 제공  
- NumPy : 파이썬으로 과학 계산을 위한 패키지.  
다차원 배열 위한 기능, 선형대수 연산, 푸리에 변환 등 고수준 수학함수와 유사(pseudo)난수 생성기 포함.  
- SciPy(사이파이) : 과학 계산용 함수 모아놓은 패키지.  
고성능 선형대수, 함수최적화, 신호처리, 특수 수학함수와 통계분포 등 많은 기능  
- matplotlib : 대표적 과학 계산용 그래프 라이브러리.  
선그래프, 히스토그램, 산점도 등  
- pandas : 데이터 처리와 분석을위한 파이썬 라이브러리  

### 구글 Colab  
클라우드 기반 주피터 노트북 개발환경 제공  
브라우저에서 python 작성과 실행이 가능하고 별도 설치 필요도 없다.  
기본적으로 데이터 분석 위한 라이브러리가 설치되어있다.  
GPU 무료로 사용 가능하고 주피터 노트북과 유사하면서 더 좋은 기능 제공한다.  
깃과 연동되어 협업 코딩 가능  

### 기계학습과 수학
기계학습에서 수학은 중요하다.  
수학을 통해 목적함수를 구하고 이를 최적화한다.  
이렇게 구한 최적화된 목적함수가 알고리즘을 구성하는 기본적인 근간이기에, 알고리즘의 원리를 이해하기 위해선 필수적  
사람을 알고리즘을 설계하고 데이터를 수집한다.  
기계학습은 수학/알고리즘/사람이 수집하는 데이터로 이루어지는 것이다.  

- 선형대수학을 통해 어떻게 조사 대상을 형식화할 것인지 알게된다.  
(학습 모델의 매개변수집합, 데이터, 선형연산의 결합 등을 벡터나 행렬로 간결히 표현가능, 데이터 분석해서 유용한 정보 알아내거나 특징 공간을 변환수행)  
- 확률과통계를 통해 데이터의 특징을 알게된다.  
(데이터에 포함된 불확실성 표현하고 처리, 데이터의 특징들 추출하고 많은 데이터의 중요한 속성만 간추리는 역할, 모델설계에 활용)  
- 최적화이론을 통해 알고리즘을 이해하고 훈련과정을 최적화한다.  
(목적함수를 최소화하는 최적해 찾는데 활용. 주로 미분)  

### 선형대수  





## 3주차  
## 4주차  
## 5주차  
## 6주차  
## 7주차  
## 8주차  