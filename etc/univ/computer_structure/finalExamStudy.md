# 컴퓨터구조 기말고사 공부
## Chapter 03
컴퓨터에서 정수의 연산(덧셈, 뺄셈, 곱셈, 나눗셈, 오버플로 다루기)과 부동소수점(표현 방법과 연산 방법)에 대해 알아본다.  

- 컴퓨터 수 표현 방법, 산수연산 알고리즘  
- 알고리즘을 위한 하드웨어 설계
- 명령어 집합에 미치는 영향  

### 정수 연산
- 덧셈 : 오른쪽에서 왼쪽으로 계산한다. 오른쪽에서 왼쪽으로 넘어가는 올림수(carries)가 발생할 수 있다.
- 뺄셈 : 7-6의 형태를 7+(-6)으로 생각하여 계산할 수 있다. 다시 말하면, 뺄셈을 할 수를 **2의 보수화** 처리한 후 덧셈 과정처럼 계산할 수 있다.  
혹은 뺄셈을 당하는 수의 MSB가 2(빌림수)가 있다는 가정을 통해 뺄셈을 할 수도 있다.  
이 과정에서 발생하는 범위밖(MSB) Carry(올림)이나 Borrow(빌림)값은 무시한다.  
- Overflow : 메모리의 허용범위를 초과하여 값이 들어오는 경우 발생  
스택 영역이 힙 영역을 침범하거나 힙 영역이 스택 영역을 침범하는 경우  
연산에서 발생하는 오버플로우는 연산 후의 결과가 하드웨어(32비트 워트)에서 표현할 수 없는 경우에 발생한다.  
MSB(부호비트)를 값 비트들이 침범해서 이상한 값으로 바뀌는 경우다.  
**다른 부호끼리의 덧셈 / 같은 부호끼리의 뺄셈은 오버플로우 발생 X** - 절댓값이 작아지는 경우이기에 오버플로우가 발생하지 않는다.  
반면 **같은 부호끼리의 덧셈 / 다른 부호끼리의 뺄셈** - 오버플로우가 발생할 수 있다. 절댓값이 증가하는 연산이기 때문이다.  

> Overflow가 발생했는지 탐지하는 방법 - MSB(부호비트)를 크기비트가 침범하여 값이 바뀌어버린다. 부호비트로 올림수가 올라가기 때문. 따라서 부호비트의 변경여부로 Overflow를 확인한다.

C,Java같은 몇몇 언어는 오버플로를 무시하여 예외처리를하지 않지만 (MIPS addu, addui, subu 명령어를 사용함)  
다른 언어들은 예외처리를 발생시킨다 (MIPS add, addi, sub 명령어 사용) 하지만 예외처리를 발생시키는 언어들 조차 예외처리는 시키지만 검사를 위한 명령어는 제공하지 않는다.  

### ALU (산술논리연산장치)
프로세서에서 연산을 담당하는 장치이다. ALU의 구성은 크게 4가지이다.  
1. 산술연산장치 : +, -, *, /과 같은 산술연산을 수행한다.
2. 논리연산장치 : AND, OR, XOR, NOT 등 논리연산을 수행한다.
3. 시프트레지스터(shift register) : 비트들을 좌,우로 이동시키는 기능을 가진 레지스터가 있다.
4. 보수기(complementer) : 데이터를 2의 보수화 한다. (음수화)

### 곱셈 연산  
- 기본 알고리즘 : 64비트의 Multiplicand(피승수), 32비트의 Multiplier(승수), 64비트의 ALU(연산장치), 64비트의 곱(Product) 를 가지고 연산을 한다.  
    1. 이진수를 기준으로승수의 LSB(가장 오른쪽 비트)를 보고 1이면 피승수를 곱에 더하고, 0이면 더하지 않는다. 
    2. 피승수를 왼쪽으로 1비트 쉬프트(shift left)하고 승수는 오른쪽으로 1비트 쉬프트(shift right)하여 단위를 위로 올려준다.  
    3. 승수의 비트 수만큼 반복 수행한다. 위 경우엔 승수가 32비트기에 32번 반복했는지 확인하고 32번 수행한 뒤에 종료하여 Product(곱)의 값을 확인한다.  
- 개선된 하드웨어 : add와 shift를 병렬적으로 수행하는 알고리즘으로 설계되어있다. 32비트의 Multiplicand, ALU로 위보다 절반 크기로 줄었고, Multiplier를 Product(곱)에 쓴 상태로 초기화하기에 별도로 필요로 하지 않는다. 64비트의 Product(곱)을 가지고 연산을 한다.    
    1. Product(곱) 하위 32비트에 Multiplier(승수)값을 초기화한다.
    2. Product의 LSB를 확인하여(Multiplier 값) 1이면 Multiplicand(피승수)를 Product 상위 32비트에 더한다.
    3. 위에서 피승수를 더하면서 저장함과 동시에 Product(곱)을 shift right해준다. 이 과정에서 승수의 단위와 피승수의 단위가 바뀌는 것과 다름없다. 올림수를 저장해야하기에 사실은  Product는 65비트이긴 하다.  
    4. 이 과정을 32번 (Product 하위 32비트 수 만큼) 반복 수행한다. 결론적으로는 Product(곱)에 있던 Multiplier(승수)는 전부 shift right되어 사라져있을것이고, Product에 더해지는 Multiplicand(피승수)는 단위가 올라가며 차근차근 더해지고, 32번 반복수행된 결과 곱의 결과가 Product에 저장되어있을것이다.  
- 더 빠른 곱셈 : 다중덧셈기를 사용하여 병렬 트리 구조로 연산을 수행한다. 덧셈기가 늘어날수록 성능은 좋지만 코스트가 영 좋지 않을것이다. 이런 TradeOff를 고려하여 디자인해야한다. 트리 구조이기에 32번의 덧셈도 log2(32)=5번의 덧셈 시간이 걸린다.

**MIPS에서의 명령어**  
MIPS에선 두개의 32비트 레지스터를 사용한다. 따라서 곱셈명령어의 결과는 이 두 레지스터에 저장이 된다. HI:most-significant 32bits(큰값들), LO:least-significant 32bits(작은값들)  
곱셈을 사용하는 명령어는 *mult rs, rt / multu rs, rt*와 같은 명령어로 rs와 rt의 값을 곱하고 그 결과는 상위 32비트(HI)와 하위 32비트(LO)에 저장된다.  
곱셈의 결과는 *mfhi rd / mflo rd* 를 사용하여 레지스터 rd로 HI와 LO에 있는 값들을 이동시킬 수 있다.  
*mul rd, rs, rt* 를 사용하여 곱셈할 수도 있지만, 결과가 32비트를 초과해버리는 경우에는 적절하지 않다. (승수와 피승수가 너무 큰 경우)  

### 나눗셈 연산  
- 기본 알고리즘 : 64비트의 Divisor(제수)레지스터는 상위 32비트에 Divisor를 넣고 시작한다. 64비트의 Remainder(나머지)엔 피제수값이 초기화 된다. 32비트의 Quotient(몫)레지스터는 0으로 초기화 시킨다.  
    1. 초기 Remainder(나머지)에 저장되어 있는 피제수에서 Divisor(제수)값을 빼준다. 그 값이 0이상인 경우와 0미만인 경우로 나뉜다.  
    2. 뺀 결과가 0이상이라면 나눌 수 있다는 것이므로, 몫을 1비트 shift left 후 LSB에 1을 저장해준다. 만약 0미만이면 나눌 수 없다는 것이니, 빼기 전 값으로 복원하고 몫 레지스터를 1비트 shift left 후 LSB에 0을 저장해준다.
    3. Divisor(제수)를 1비트 shift right하여 다음 계산을 위해 피제수에 맞추어 제수를 정렬한다.  
    4. 위 과정들을 총 33번 반복한다. 32비트의 제수를 가질 때 n+1번이니, 반복횟수는 33번인 것이다.  
- 개선된 하드웨어 : 곱셈 개선 하드웨어와 같은 하드웨어를 사용한다. 32비트로 감소한 Divisor(제수)레지스터,ALU와 64비트의 Remainder(나머지)레지스터를 사용한다. 제수가 오른쪽으로 shift할 필요가 없고 피제수 레지스터와 몫 레지스터가 모두 Remainder에 저장되기에 필요없다.   
    1. 초기에 제수는 Divisor에 저장되고, Remainder 하위 32비트에 피제수가 저장된다.  
    2. Remainder의 상위 32비트(사실 33비트)에서 Divisor(제수)를 빼고 그 결과를상위 32비트에 넣는다. 결과가 0이상(양수)이면 Remainder(나머지)를 shift left하고 LSB를 1로 둔다. 결과가 0미만(음수)면 다시 원래값으로 복원하고 shfit left한 뒤 LSB를 0으로 넣는다.  
    3. 위 과정을 반복하면 왼쪽 상위 32비트는 나머지가 저장되고, 오른쪽 하위 32비트는 몫이 위치하게 된다.  

부호가 있는 나눗셈들에선 나머지를 출력하는 기준이 있다.  
제수와 피제수 부호가 다르면 몫은 음수이고,
**피제수와 나머지의 부호가 항상 같도록 하는것이 원칙**이다.  
예를들어 제수:-2, 피제수:7인 상황이면, (7/(-2)) 몫:-3, 나머지:1로 한다. 수학공식이랑 다름(q=내림(a/b)이라 수학 공식대로하면 몫:-4, 나머지:-1이다)  

나눗셈은 곱셈처럼 병렬적 연산은 수행할 수 없지만, SRT devision이라는 알고리즘을 통해 각 단계마다 여러 몫비트를 예측하는 기법(현재는 4비트씩)을 사용하여 빠른 계산이 가능하다.  

**MIPS에서의 명령어**  
곱셈과 마찬가지로 결과값이 HI/LO 레지스터를 활용되어 저장된다.  
*div rs, rt / divu rs, rt* 를 사용하여 나눗셈을 사용할 수 있고, **HI에 32bits 나머지, LO에 32bits 몫**이 저장되기에 *mfhi, mflo* 를 통해 값을 사용할 수 있다.  

### 부동소수점
정수가 아닌 수를 표현할 때 부동소수점을 사용한다.  
또한 부동소수점을 사용하면 매우 작은수부터 매우 큰 수까지 나타낼 수 있다.  
C언어에서는 float 혹은 double이 부동소수점 방식에 속한다.  
> 컴퓨터 이진수에서 표현되는 형태는 아래와 같다.  
$+-1.xxxxxxx(2) * 2^{yyyy}$  

부동소수점은 비트 수에 따른 표현방식이 두가지 있다.  
- 단일 정밀도 (Single precision, 32-bits)  
- 2배 정밀도 (Double precision, 64-bits)  

정수가 아닌 수를 나타내가 위해 **고정소수점**이라는 직관적인 방법을 사용하기도 하였다. 하지만 구현이 편하다는 장점 빼고는 표현가능 범위도 적고, 정밀도도 낮은 문제때문에 거의 사용되지 않는다.  
> 10진수 7.625는 2진수로 111.101이고, 이를 고정소수점으로 나타내면 부호비트:0, 정수부:0000111, 소수부:10100000 이런방식

결국 고정소수점보다 부동소수점이 더욱 유용하게 사용되고 있다.  
> 부동소수점 방식으로 위에서 나타낸 7.625를 나타내면 111.101을 1.11101*2^{2}으로 먼저 바꿔주고, 지수부는 2기때문에 10, 가수부는 111101이 된다. (1 + .11101)  
결국 부호비트:0, 지수부:2+127(바이어스)=10000001, 가수부:11101000... 이다.  

단일정밀도와 2배정밀도가 표현하기 위한 비트수가 다른만큼 지수필드와 가수필드의 크기가 다르다.  
**단일정밀도** - 부호비트 1, 지수필드 8, 가수필드 23비트   
**2배정밀도** - 부호비트 1, 지수필드 11, 가수필드 52비트  
- 둘다 지수필드에 bias라는 값을 더해서 비트에 기입해넣는데, 그 이유는 음의 지수값을 표현하기 위해서이다.  
따라서 단일정밀도는 127을 bias로 더하여 2^{-126}에서2^{127}을 나타내고, 2배정밀도는 1023을 bias로 하며 2^{-1022}에서2^{1023}을 나타낼 수 있다.  

**부동소수점의 표현 형식**  
$x = (-1)^s * (1+Fraction;지수필드) * 2^{Exponent;지수필드-Bias}$  

부동소수점 표현에서 지수필드는 -126에서127(2배정밀도는 -  1022에서1023)을 나타낸다 했는데, 왜 8비트에서 -127에서128이 아닌, 좀 더 작은 범위일까?  
**그 이유는 00000000과 11111111은 다른 수를 표현하기 위한 특수비트들이기 때문이다.**  
00000000은 잠복비트가 없음을 나타내기에 수가 0.xxxx인 경우에 -127의 지수, 0.f의 유효숫자를 갖는다는걸 의미한다. 또한 가수필드도 000...이면 전체 수는 0을 나타낸다.  
11111111은 가수필드가 모두 0이거나 모두0이 아닌경우로 나뉘는데 가수필드가 모두 0이면 무한대 혹은 -무한대이고, 모두 0이 아니면 NaN값이다.  

따라서 단일정밀도에서 표현하는 가장 작은수와 가장 큰수를 나타낼 때 지수는 00000001와 11111110이다. (-126, 127)  
가수는 000...00으로 유효자리가 1.0인 경우와 111..11인 경우로 유효자리가 거의 2.0에 근접하는 경우이다.  
두 경우 나타내어지는 수는  
+-1.0 * 2^{-126} = +-1.2 * 10^{-38}과  
+-2.0 * 2^{+127} = +-3.4 * 10^{+38}이다.  

2배 정밀도에서도 비트만 달라지고 경우는 똑같다.  
+-1.0 * 2^{-1022} = +-2.2 * 10^{-308}  
+-2.0 * 2^{+1023} = +-1.8 * 10^{+308}이다.  

**Overflow와 UnderFlow (오버플로와 언더플로)**  
표현가능한 범위가 넓긴한데 그래도 범위가 존재하긴하니까 Overflow와 UnderFlow가 발생할 수 있다.  
- Overflow는 주어진 표현방식의 범위를 넘어선 수가 입력될때 발생하고 값이 변경되는 심각한 오류가 발생하게 된다. 예를들어 단일정밀도에서 1.0 * 2^{130}이 입력되면 발생한다.  
- Underflow는 주어진 표현방식의 범위가 수를 정확히 표시하기엔 부족해서 소수부분을 정확히 표현할 수 없을 때 발생한다. 근데 그리 큰 오류가 아니다. 1.0 * 2^{-130} 이런 경우에 발생  

> 예시로 -0.75를 부동소수점으로 표현하면, 먼저 이진수로 나타낸다.  
0.75 * 2 => '1'.5 * 2 => '1'.0 이니 0.11(2)이고 이는 1.1 * 2^{-1}이다.  
단일정밀도 - 부호비트 : 1, 지수필드 : -1+127 = 126 = 01111110(2), 가수필드 : 100000...(2)  
2배정밀도 - 부호비트 : 1, 지수필드 : -1+1023 = 1022 = 01111111110(2), 가수필드 : 1000...(2)  

> 반대의 경우도 구한다. 11000000101000...00가 단일정밀도 표현일때 어떠한 수인지 구해보면, 1(부호비트) 10000001(지수필드) 01000..000으(가수필드) 이렇게 세 부분으로 나눈다.  
지수필드가 129이기에 -127 = 2이나온다. 정리해서 작성하면 -1.01 * 2^{2} 이다. 이는 -101.0이고, 10진수로 나타내면 **-5.0** 이다.

### 부동소수점 덧셈  
부동소수점은 덧셈을 하기 위한 단계가 존재한다.  
1. 소수점을 큰 지수 기준으로 맞춘다.  
예를들어 10진수 4비트 상황에서 9.999 * 10^1 + 1.610 * 10^{-1}이 있다면 9.999 * 10^1 + 0.016 * 10^1로 맞추어준다.
2. 유효숫자를 더한다.  
9.999와 0.016을 더해 10.015 * 10^1으로 만들어준다.
3. 정규화와 오버플로/언더플로 검사를 한다.  
1.0015 * 10^2로 변환된다. 근데 4비트 표현범위를 벗어남  
4. 필요하다면 반올림 후 다시 정규화/검사를 한다.  
4비트에 맞게 1.002 * 10^2 로 반올림했다. 정규화가 다시 필요하지 않으니 이상태로 마무리  

> 이진수도 위 과정과 동일하다고 보면 된다.  
1.000 * 2^{-1} + -1.110 * 2^{-2} 상황  
1.000 * 2^{-1} + -0.111 * 2^{-1} 로 지수를 맞추어준다.  
0.001 * 2^{-1}로 유효숫자끼리 더한 값을 낸다.  
정규화하여 1.000 * 2^{-4}으로 만든 후 오버플로 언더플로 검사  
비트수가 맞기에 반올림 필요 없다.  
10진수로 바꾸면 0.0001에서 1.0 / 2 = 0.5 => 0.5 / 2 = 0.25 => 0.25 / 2 = 0.125 => 0.125 / 2 = 0.0625 이다.  
(0.0001에서 뒤에부터 가져와서 '1'.0 / 2 = 0.5 이고 그 다음엔 1앞에 있는 '0'.5 인데 이 .5는 위에 1.0/2에서 구한 소수점을 가져온다)
따라서 답은 0.0625  

### 부동소수점 하드웨어  
정수 덧셈보다 당연히 훨씬 복잡하다.  
그래서 한 클럭 사이클동안 이루어지기에는 너무 길다!  
따라서 부동소수점 덧셈기는 여러 클럭사이클로 이루어져있고, 파이프라인화가 될 수 있다.  
1. 지수 비교, 비교 후 더 작은 지수를 큰 지수에 맞추어 지수값을 shift left해줄것이기에, 작은 지수를 갖는 수의 지수에 맞춰 가수필드를 right로 shift해준다.  
2. Big ALU를 통해 가수필드 더하여 유효숫자를 더해준다.  
3. 더해진 유효숫자를 정규화하기 위해 1.xxx 형태가 되도록 가수필드를 shift left or shift right 해준다.  
4. 표현가능한 비트수에 맞게 반올림하고 반올림이 필요없다면 그대로 값을 내고, 반올림을 한 이후 정규화가 추가로 필요하다면 정규화 과정으로 다시 돌아간다.

부동소수점 곱셈기는 덧셈기와 비슷한 복잡도를 갖는다. 유효숫자의 곱셈을 진행하면 됨.  
부동소수점 산술연산 하드웨어는 덧셈, 뺄셈, 곱셈, 나눗셈, 역수, 루트 등을 수행하고 대개 여러클럭 사이클을 소요하기에 파이프라인화가 될 수 있다.  

- 부동소수점 연산은 보조프로세서를 활용한다.  
단일정밀도는 $f0, $f1... $f31의 프로세서를 활용하고  
2배정밀도는 $f0을 사용하기위해 $f0/$f1을 사용.. $30까지 총 16개 사용가능하다.  
- 부동소수점 명령어는 부동소수점 레지스터($f...)에서만 동작한다  
- lwc1, l.d, swc1, s.d와 같은 형태로 명령어사용  
단일정밀도는 .s이고 2배정밀도는 .d가 붙는다.  
add.s, sub.s, mul.s, div.s처럼 사용가능  
add.d, sub.d, mul.d, div.d는 2배정밀도 경우임  
2배정밀도는 2개씩 레지스터를 사용하기에 mul.d $f4, $f4, $f6처럼 짝수단위로 사용해야할것.  
비교명령어 eq, lt, le같은 기능은 c.xx.s, c.xx.d로 사용할 수 있다.  
분기명령어는 bc1t, bc1f(true, false)로 사용한다. cond비트가 참이거나 거짓일때 목적레이블로 분기함  

## Chapter 04
### 프로세서  
CPU의 성능을 결정하는 요소는 명령어의 수, 클럭사이클시간(CPI:명령어당 클럭 수)이다.  
명령어 수는 ISA와 컴파일러에 의해 결정되고, CPI는 CPU하드웨어(또는 프로세서 구현방법)로 결정된다.  

MIPS를 구현하는 하드웨어를 살펴본다.  
물론 명령어 집합의 일부만 구현해보는데,  
- 메모리 참조의 lw, sw  
- 산술/논리 명령어의 add, sub, and, or, slt
- 조건부 분기 명령어의 beq, j

**명령어를 구현하기 위해 필요한 구성요소는 다음과 같다.**  
프로그램카운터(PC), 덧셈기, 명령어메모리, 레지스터파일(레지스터모음구조), ALU, 데이터메모리, 제어유닛, 제어신호, 데이터신호, 멀티플렉서(MUX)혹은AND게이트  

모든 명령어에 공통적으로 포함되는 두가지 구성요소  
*프로그램 카운터(PC)* : 명령어 메모리에 참조하여 다음에 실행할 명령어를 가져온다.  
*레지스터파일* : 읽을 레지스터를 선택하는 명령어필드로 하나or두개의 레지스터를 읽는다.  

명령어는 종류에 따라 이후 과정이 결정되는데 세가지 명령어 종류는 대부분 비슷하고, MIPS명령어 집합은 단순,규칙적이라 실행이 다들 비슷하고 구현이 간단하다.  
> 예를 들어 점프명령어를 제외하면 모두 레지스터를 읽고 ALU를 사용하는 구조이다.  

**ALU의 사용**  
- 메모리 참조 명령어는 주소계산을 위해 (offset을 더함) 덧셈을 사용
- 산술/논리 명령어는 연산을 위해 ALU를 사용. ALU 목적 그자체
- 분기 명령어는 비교하기 위해 (a-b가 0이면 a==b) 뺄셈을 사용

> 하지만 사용되고 난 이후과정은 서로 다르다.  
메모리 참조 명령어는 메모리에 접근하여 읽거나 쓰고,  
산술/논리 혹은 적재명령어는 레지스터에 다시 쓰는 과정이 필요하고,  
분기 명령어는 PC+4를 쓸지 PC+4+offset의 주소를 PC로 쓸지.. 

**조합소자**  
AND-gate : Y = A & B  
Adder : Y = A + B  
Multiplexer : Y = S ? l1 : l0  
Arithmetic/Logic Unit : Y = F(A, B)  

**상태소자**  
레지스터 : 데이터를 저장함  
저장된 값을 업데이트하는 시기를 정하기 위해 클럭시그널을 활용하는데, 일반적으로는 *'상향 엣지-구동'*으로 클럭이 0에서 1로 바뀔 때 값을 업데이트한다.  

클로킹을 할때는, 조합논리회로(combiational logic circuit)의 길이가 클럭 사이클을 결정한다.  
상태소자에서입력, 다른 상태소자로 출력까지 하나의 조합논리회로에서 걸리는 시간 중 가장 긴 시간이 클럭 사이클 시간으로 결정된다.  

### 데이터패쓰
MIPS명령어들이 어떤 데이터패스로 구현할 수 있는지 단일클럭사이클을 기준으로 만들어본다.  
구성요소로는 레지스터, ALU, MUX, 메모리 등이 있다.  

- Fetch (명령어 가져오기) : PC(프로그램카운터)에서 다음에 실행할 명령어를 가져오는것을 의미한다. 일반적으로는 PC+4를 통해 다음 명령어의 주소를 가져와서 다음에 실행될 명령어로 향하지만 혹여나 분기명령어를 만난다면 PC+4+offset을 통해 분기된 곳의 명령어를 다음 명령어로 사용한다.  
- R-Format 명령어 : R-format은 레지스터파일에서 2개의 레지스터를 피연산자로 읽는다. 그리고 피연산자들을 사용해서 산술/논리 연산을 수행하고 '레지스터쓰기' 제어신호를 바탕으로 레지스터에값을 쓴다.  
- 적재/저장 명령어 : 적재/저장 명령어는 레지스터 피연산자를 하나 읽고 16비트 offset으로 메모리 주소를 계산한다.(ALU, 부호확장된 오프셋 활용) 적재는 메모리를 읽고 레지스터를 업데이트하고 저장은 데이터 메모리에 값을 업데이트한다.  
- 분기 명령어 : 레지스터 피연산자를 하나 읽는다. ALU를 활용하여 피연산자를 비교하고, 그 결과가 0인지 아닌지를 통해 특정 로직으로 이동한다.  
이동할 때 목적주소를 계산하는데 부호확장된 오프셋을 활용하고 결과를 2비트 쉬프트하여 워드단위를 바이트단위로 바꾸어준다.  
그리고 그 값을 PC+4에 더하여 (PC+4)+offset 위치로 분기한다.

첫번째 단계에서 데이터패스는 한클럭 사이클 안에 명령어를 수행함. 각 데이터패스 요소는 한번에 하나의 기능만 수행한다.  
같은 패스를 서로 다른 명령어가 활용한다. MUX를 활용하여 서로 다른 데이터 소스를 적용할수 있다.  

R-Type / 적재 / 저장 데이터패쓰는 묶어서 하기 좋음 (셋다 ALU 덧셈을 사용)  
전체 데이터패쓰를 보면 **ALU 제어기능**을 넣어 여러방향으로 사용가능하게 한다. 적재/저장은 add, 분기는 sub, R-type은 funct필드로 결정된다.  

- ALU 제어기능 : 4비트 제어입력으로 ALU를 제어한다.  
0000이면 AND, 0001이면 OR, 0010이면 add, 0110이면 subtract, 0111이면 set-on-less-than(slt), 1100이면 NOR을 나타낸다.  

op코드 6비트(31-26)로 먼저 2bit의 ALUOp를 만든다.  
000000(0)은 R-Type이니 10을 출력하고  
100011(35)와 101011(43)은 load/store이니 00을 출력하고  
000100(4)는 beq이니 01을 출력한다.  
이렇게 만든 ALUOp가 만약 10(2)이라면 6비트의 funct(5-0)와 조합하여 ALU control 4비트를 만든다.  
100000이 들어왔다면 add => 0010  
100010이 들어왔다면 subtract => 0110  
100100이 들어왓다면 AND => 0000  
100101이 들어왔다면 OR => 0001  
101010이 들어왔다면 slt => 0111   


- 점프 명령어 : jump는 기존PC의 상위 4비트 + 26비트의 점프 주소로 이루어져있다. 주소는 워드단위로 적혀있기에 00을 붙여서 (shift left 2칸) 바이트단위로 만들어준다.  

### 성능 이슈
사실 이런 데이터패쓰를 만들면 명령어 중 가장 오래 걸린 시간이 클럭주기가 된다.  
위에선 적재명령어가 가장 오래걸린다.  
명령어메모리 -> 레지스터파일 -> ALU -> 데이터메모리 -> 레지스터파일  
이런 단계를 거치는데 단일사이클에서는 서로 다른 명령어들에 대해 걸리는 시간을 바꿀수가 없다.  
그래서 멀티사이클로 각각 명령어를 처리하고, 파이프라이닝을 통해 성능 개선할 수 있다.  

### 파이프라이닝
실행들이 한 실행이 다 지나고 다음 실행이 이루어지는 방식을 사용하지 않고, 구역별로 나누어져서 실행들이 겹쳐질 수 있게하여 병렬화를 통해 성능을 개선하는 것을 말한다.  
> 예를 들어 빨래라는 과정이 파이프라인화가 되어있지 않으면 (세탁+건조+정리+수납) 이 과정들이 하나의 행동으로 묶여있어서 여러번의 빨래를 하려면 위 모든 과정을 다 거치고 다음 빨래를 진행한다.  
하지만 파이프라인화로 세탁, 건조, 정리, 수납 이렇게 네 가지의 과정으로 분리되어 있으면 첫 번째 빨래의 세탁이 마친 이후 건조를 하는 동안 두 번째 빨래의 세탁이 시작될 수 있다.  
이렇게 실행들이 병렬화되어 수행된다면 더욱 빠른 속도로 실행들을 수행할 수 있을 것이다.  

**MIPS 파이프라인의 다섯개 스테이지**  
1. IF (Instruction fetch from memory) : 메모리에서 명령어를 가져오는 스테이지  
2. ID (Instruction decode & register read) : 명령어를 해독하면서 레지스터를 읽는 스테이지. MIPS 명령어는 규칙적이라 이것을 동시에 할 수 있다.
3. EX (Execute operation or calculate address) : 연산을 수행하거나 주소를 계산하는 스테이지
4. MEM (Access memory operand) : 데이터 메모리에 있는 피연산자에 접근하는 스테이지
5. WB (Write result back to register) : 결과값을 레지스터에 쓰는 스테이지

레지스터를 읽기/쓰기 하는 스테이지(ID)는 100ps이고 나머지는 모두 200ps의 시간을 갖는다고 가정한다.  
단일사이클 데이터패쓰와 파이프라인화 된 데이터패쓰를 비교하면 매우 큰 차이가 난다.  

단일사이클의 경우는 한클럭사이클이 IF,ID,EX,MEM,WB(200+100+200+200+100) 800ps이다.  
반면 파이프라인화 된 데이터패쓰는 가장 긴 실행시간을 갖는 스테이지를 기준으로 한클럭사이클 시간을 정할 수 있고, 그리하여 200ps가 한클럭사이클 시간이 된다.  
만약 이 프로그램을 3번 실행시켰을 때, 단일사이클은 800 * 3 = 2400ps의 시간이 걸리겠지만, 400+900=1300ps가 걸린다.  

*파이프라인의 속도 향상률은 모든 스테이지가 같은 시간이 걸린다면*  
파이프라인화된 데이터패쓰에서 명령어 사이시간 = 단일사이클에서의 데이터패쓰에서 명령어 사이시간 / 스테이지 수 (파이프 단계수) 이다.  

MIPS 예시처럼 다 같은 시간이 걸리지않는 논밸런스상황이면 속도향상은 작아진다. 속도향상은 명령어 처리량을 증대시켜서 생긴다. (throughput 향상)  
단, 하나의 명령어의 실행시간은 줄지 않는다. (당연하지)  

### 파이프라이닝을 위한 명령어집합(MIPS) 설계
- 파이프라이닝을 하기 쉽게 모든 명령어를 32비트로 같은 길이로 만들었다. 그 덕에 한클럭사이클 동안명령어를 가져오면서 디코드를 할 수 있다.  
- 적은 종류의 명령어 형식을 갖는다 (format)  
- 메모리 피연산자를 직접 연산할 수 없다 - 그래서 연산단계, 메모리에 값을 쓰거나 읽는 단계로 나누어져있다.  
- MIPS 피연산자는 메모리에 정렬되어 있다 - 한번 사이클동안 적재/저장이 일어나면, 메모리에 한번만 접근하면 된다  

### 파이프라인 해저드(Hazard)
다음 명령어가 다음 클럭사이클에 실행될 수 없는 상황이 있다.  
- 구조적 해저드 : 주어진 클럭 사이클에 실행되도록 하는 명렁어 조합을 해저드가 지원하지 못해서 실행될 수 없는 경우.  
하드웨어 설계상 같은 클럭사이클에 같이 실행될 수 없는 경우인데 MIPS는 처음부터 파이프라이닝 고려하고 디자인해서 이런건 쉽게 피해진다.  
MIPS에서 예를들어 데이터 메모리와 명령어 메모리가 하나의 메모리라면 적재와 저장은 메모리 데이터에 접근할 때 명령어를 메모리에서 가져오는 동작과 충돌이 생겨서 지연됨. 지연과정은 거품(bubble)이라고도 불림.
- 데이터 해저드 : 이전 명령어의 결과를 기다려야 다음 명령어가 실행될 수 있는 경우 (예를들어 이전 명령어의 연산결과를 바탕으로 다음 명령어가 연산을 진행)  
**해결** - 계산된 즉시 결과를 활용할 수 있도록 하드웨어에 직접적인 연결을 하여 '전방전달(우회전달)' 한다. 데이터패쓰에 추가적인 연결이 필요한 방법이다. 대신 레지스터에 저장될때까지 기다리지 않는다.  
근데.. 전방전달로도 지연을 못피하기도 한다. load는 offset계산 후 메모리에 접근하여 값을 가져오는데, 이건 네번째 스테이지에서 이뤄지는 과정이라 전방전달을 해도 하나의 지연이 생긴다.  
이럴때는 바로 다음에서 결과를 쓰지 않고 더 뒤에 사용하도록 코드를 수정하면 된다.  
- 제어 해저드 : 이전 명령어로 인해 제어실행이 결정되는 경우 (에를들어 이전명령어 결과로 그 다음 실행할 명령어가 결정되는 경우. 분기명령어 같은것이 예시)  
근데 분기명령어는 제어의 흐름을 정하는데 다음 명령어로 무엇을 가져올지 분기에 따라 크게 바뀐다. 따라서 분기명령어로 인해 제어해저드가 발생하는 경우 잘못된 명령어를 가져올 수 있다.  
**해결**을 위해선 레지스터 비교, 목적주소계산을 빨리하는게 필요하다. 이를 위해 MIPS파이프라인에선 분기의 ID단계에 하드웨어를 추가한다.  
근데 이렇게 ID단계(두번째 스테이지)에서 결과를 알아도 바로 다음 명령어를 가져오는 과정에선 지연이 생긴다. 분기명령어의 CPI가 사실상 2가 되는 상황.. 지연으로 인한 패널티가 너무 심하다!  
새로운 해결 방법은 분기 결과를 예측하는 것이다. 이러면 예측이 틀릴때만 지연이 발생한다.  
예측방법은 상황마다 다르다. 그렇기에 보편적 행동에 의존해서 예측을 하는데 예를들어 보통 반복문은 꼭대기로 분기할 확률이 높기에 꼭대기로 분기하는 것을 예측할 수 있다.  
이렇게 보편적 행동에 의존하는 **정적 분기 예측 방법**이 있고,  
하드웨어가 각 분기 명령어별로 분기된 정도를 기록하여 분기정도를 측정하고 그에 맞게 더 높은 확률로 예측하는 **동적 분기 예측 방법**이 있다.  

### 파이프라인 요약  
- 파이프라이닝의 목적은 명령어 처리량을 증가시켜서 성능의 증가로 이어지기 위해. 병렬연산을 통해 여러 명령어를 동시실행한다. 또한 각 명령어는 같은 지연시간을 갖는다.  
- 해저드 종류 : 구조 해저드 , 데이터 해저드, 제어 해저드  
- 명령어집합의 디자인은 파이프라인 구현을 할 때 복잡도에 영향을 준다.  

**MIPS 파이프라인 데이터패쓰**  
IF로 명령어 인출  
ID로 명령어 해독 및 레지스터 파일 읽기  
EX로 실행 또는 주소 계산  
MEM으로 데이터 메모리 접근  
WB로 레지스터에 쓰기  

쓰는 과정에서 데이터해저드가 일어날 수 있고,  
오른쪽에서 왼쪽 흐름은 다음 명령어에 영향을 주고 제어해저드 발생할 수 있다.  

**파이프라인 레지스터**  
파이프라인에 스테이지마다 사실은 레지스터가 필요하다. 왜냐면 이전 사이클에서 생성된 정보(데이터신호, 제어신호)를 저장하기 위해서이다.  

**파이프라인 표현**  
사이클별 명령어 흐름을 표현하는 방식이 크게 두개 있는데,  
한 사이클 내에서 파이프라인이 어떻게 활용되는지 보여주는 **단일 클럭 사이클** 파이프라인 다이어그램, 전체적으로 시간이 지남에 따라 동작을 보여주는 **다중 클럭 사이클** 파이프라인 다이어그램이 있다.  

단일 클럭 사이클 파이프라인 다이어그램은 각 스테이지 별로(사이클 별) 어느 부분들이 사용되는지 영역이 색칠되어 표기된다. 오른쪽이 색칠되어 있는 것은 읽기, 왼쪽이 색칠되어 있는 것은 쓰기이다.  

다중 클럭 사이클 파이프라인 다이어그램은 전체적인 실행에서 활성화 영역을 각 클럭사이클 순서대로 보여준다. 전반적으로 보기 편하다는 장점도 있고, 하나하나를 떼어내서 보면 단일 클럭 사이클처럼 볼 수도 있다.  

**파이프라인 제어**  
파이프라인 제어신호는 Control에서 IF, ID 단계를 거쳐 EX단계부터 나타나기때문에 ID단계에서 생성하여 파이프라인 레지스터를 통해 이후 스테이지들에게 전달된다.  
EX, MEM, WB에 사용할 제어신호들을 한번에 데이터패쓰 레지스터에게 전달하고, 각 스테이지에서 사용할 제어신호들을 활용하고 남은 애들을 다음 스테이지쪽 데이터패쓰 레지스터에게 전달해주는 방식으로 흐름이 이어진다.  


## Chapter 05
### 메모리 계층구조
메모리는 설계 목적이 큰 용량의 메모리를 빠르게 접근하도록 설계하는게 목적이다.  
하지만 큰 용량과 빠르게 접근하는 것은 Trade-Off관계이다.  
빠른 접근이 가능한 메모리는 가격적으로 비싸기때문에 큰 용량으로 사용하기 어렵다.  
또한 큰 용량의 경우엔 메모리 주소 디코드가 시간이 더 오래 걸려서 빠른 접근이 어렵다.  
**메모리 계층구조는 이런 Trade-Off를 해결하여 성능개선하는 것이 목표이다**  
지역성을 통해서 해결하려할 수 있다.  

### 지역성  
- 시간적 지역성 : 최근에 접근된 아이템은 곧 다시 필요한 경우가 많다. 예를들면 반복문에서의 명령어  
- 공간적 지역성 : 최근에 접근된 아이템의 근처 아이템이 곧 다시 필요로 되는 경우가 많다. 예를들면 연속적인 명령어 혹은 배열 데이터  

지역성을 고려할 시엔 메모리 계층구조를 활용하면 성능향상에 큰 도움이 된다.  
메모리 계층구조 예시는 레지스터-메인메모리, 메인메모리-디스크, 메인메모리-캐시메모리 이런것과 같다...  
정확히는 레지스터 < 캐시메모리 < 메인메모리 < HDD(하드디스크)  
이 순서로 용량이 커진다. 속도는 레지스터쪽으로 갈수록 더 빠르다.  

- 레지스터 : CPU에 위치한 고속메모리로 CPU가 바로 사용 가능하다.  
- 캐시 메모리(SRAM 활용) : 대용량의 메인메모리 접근을 빠르게 하기 위해 CPU칩 내부 혹은 바로 옆에 탑재하는 메모리  
L1캐시는 코어 안에 내장, L1캐시에서 데이터 찾지 못하면 L2캐시를 참조하는데 L2는 상대적으로 속도가 느리고 대용량이다.
- 메인 메모리(DRAM) : 주기억장치. 컴퓨터의 수치,명령,자료 등을 기억하는 하드웨어 장치이다. RAM, ROM으로 구성되어 있고 상대적으로 느리지만 저렴한 가격과 대용량을 저장할 수 있는 DRAM을 RAM으로 사용한다.  
RAM이 휘발성기억장치로 데이터를 단기간 저장하고 전원유지되는 동안에는 CPU연산,동작에 필요한 모든 내용 저장  
ROM은 영구히 저장하는 비휘발성 메모리. 변경 가능성 희박한 기능이나 부품에 사용한다.  
- 보조기억장치 : 비휘발성 데이터 저장소로 대표적으로 하드디스크(HDD; Hard Disk Drive)와 SSD(Solid State Drive)가 있다.  

### 메모리 계층에서 데이터 탐색  
프로세서가 요구하는 데이터를 찾을때 프로세서가 필요로하는 데이터가 상위레벨 메모리에 있으면 해당 데이터를 찾고 (적중;Hit), 상위 레벨에 없다면 하위 계층 메모리에 접근해서 데이터를 가져온다 (실패;Miss)  

- 적중의 경우 - 적중률은 적중수/접근수, 적중시간은 메모리접근시간+데이터유무판단시간  
- 실패의 경우 - 실패율은 실패수/접근수 = 1-적중률  
실패손실(시간)은 하위계층에 접근하여 데이터를 가져와서 프로세서로 보내는 시간을 의미한다.

데이터를 가져오는 단위는 블록(또는 라인)단위이다. 블록은 여러 워드가 될 수 있기에 공간적 지역성을 이용한 것이라고 볼 수 있다. 여기에 최근 접근한 데이터를 상위 계층으로 가져온다면 시간적 지역성도 사용하는 것일듯  

### 캐시메모리  
레지스터와 메인메모리 사이의 중간단계이다.  
프로세서에서 가장 가까운 메모리로서 여러 블록으로 구성되어있다.  
캐시메모리는 블록이 한 워드인 상황에 한 계층의 캐시를 고려함.?  

캐시 방법 **직접 사상 캐시(Direct mapped cache)**를 사용한다.  
메모리 워드를 캐시에 저장하는 방법이고, 캐시의 몇번째 블록에 저장될지 캐시위치를 정한다. 이 방법은 워드의 메모리주소를 활용하는 방법이다.  

- 직접 사상 캐시 : 저장될 블록의 캐시 위치는  
'메모리에서의 블록주소' Modulo '캐시의 블록개수' 이다.  
큰 크기의 메모리에 있는 블록을 상대적으로 작은 크기를 갖는 캐시블록에 저장하는 것이다.  
어떻게 이것이 가능할까?  

캐시의 모든 블록은 각각 태그와 유효비트를 갖는다.  
**태그(Tag)**를 통해 블록의 메모리주소도 캐시에 저장된다. 데이터는 물론 저장!  
이때 상위 몇비트만 해당 주소를 나타내는데에 필요하고 하위비트들은 캐시 위치로 알 수 있다. 여기서 상위비트가 '태그'이다.  

태그와 유효비트가 언제사용되나면, 캐시에 01001이 저장되어있는지 확인한다 했을때 01/001로 보면, 001위치의 블록 태그가 01인지 확인하면 된다. 그리고 유효비트는 해당(캐시)블록이 비어있는지 비어있지 않는지를 나타내는 비트이다.  
만약 블록이 비어있으면 태그를 확인하는 과정 자체가 비효율적이라 유효비트 하나만으로 태그확인을 최소화 하는것이다. 비어있으면 0(No), 비어있지 않으면 1(Yes)를 값으로한다. 초기값은 0이다.  

> 예를들어 캐시에 00010이 저장되어있는지 확인할 때, 010블록이 유효비트를 0을 갖고있다? 아무것도 저장되어있지 않다. tag 비교까지 필요하지 않다.  

- 다른 사상 방식의 캐시 : 완전 연관 사상, 집합 연관 사상  
완전연관사상은 메모리주소에 상관없이 어떤 캐시블록에도 저장이 가능한 방식인데, 메모리 주소를 기억해야해서 태그 길이가 많이 길다. 물론 직접사상에 비해선 적중률은 높지만 태그 길이때문에 속도가 느리다.  
집합연관사상은 직접사상+완전연관사상을 한 것이다. 블록을 집합처럼 만들고 그 집합안에서 완전연관사상을 진행한다.  


### 캐시예시 
예로 캐시메모리가 000-111의 범위의 index가 존재한다. 8개의 블록이고 1블록당 1워드. 직접사상캐시라면...
1. 예를 들어 워드주소로 22가 들어온다? => 10110이 들어오고 값이 존재하지 않으니 '실패'이다. index(캐시블록위치)는 110이고 태그는 10이다. 데이터는 Mem[10110]으로 메모리에서 가져온다.  
2. 워드 26주소가 들어온다. => 11010. 값존재X => '실패'. index는 010이고 태그는 11. 데이터는 Mem[11010].  
3. 22, 26이 들어오면 둘다 데이터가 캐시에 존재하기에 적중, 적중 
4. 16이 들어오면 10000 , 실패 , index는 000이고 태그는 10.  
3이 들어오면 00011, 실패, index는 011이고 태그는 00.  
다시 16이 들어오면 적중이기에 금방 넘어간다.  
5. 워드 18 주소가 들어오면 10010이다. 위에 있던 26(11010)과 index가 겹친다.. **블록의 경쟁(competition)이 발생**  
'실패', index는 010, 태그를 10으로 바꾼다. 가장 마지막에 들어온 값으로 경쟁 후 변경되는 것이다.  

이 예시는 블록사이즈가 작을때에 예시이다. 하지만 64개의 블록, 한블록당 16바이트라고하면 어떻게 될까? 예를들어 1200메모리주소를갖는 아이템은 어느 블록에 저장될지 예측할 수 있다.  
블록단위주소로 내림(1200/16)을 하면 75가 나온다. 블록단위로 주소가 이루어지기에 75mod64 = 11 이다. 11번째 블록에 1200주소의 아이템이 저장될 것이다.  

**블록사이즈의 영향**  
더 큰 블록은 실패율을 줄일 수 있다. 공간지역성이 늘어나기때문!  
그런데 캐시 용량이 한정적인 상황에서 **블록사이즈가 커진**다는것은 **블록의 수가 감소**한다는것.  
이 말은 블록 경쟁이 자주 발생하고 실패율이 증가한다는 것이기에 블록이 계속 교체되면 시간지역성을 만족하지 못하게 된다.  
따라서 **적절한 블록 사이즈가 필요**하다.  

**캐시 실패가 미치는 영향**  
캐시가 적중하면 프로세서는 정상작동하지만 실패한다면  
CPU파이프라인이 지연이 생기고.. 계층 하위레벨에서 블록을 가져와야하기에 시간지연이 생긴다.  
만약 명령어 캐시 실패를하면 명령어 패치(IF)를 다시 시작한다.  
데이터 캐시 실패의 경우에는 데이터 접근을 완료한다.  

### 쓰기에서의 캐시적중 처리  
쓰기는 읽기랑 좀 다르다. 쓰기데이터가 만약 캐시에 있으면 캐시의 블록만 업데이트하면 문제가 된다. 왜냐면 **캐시랑 메모리 값이 불일치!**  
- 따라서 쓰기에서는 *즉시쓰기(write through)*를 사용하여 메모리를 쓰는것과 동시에 업데이트한다. 이 방법을 통해 메모리와 캐시값이 항상 같다는 장점이있다. 단, 시간은 오래걸린다. 예를들어 CPI가 1이고 명령어 10%가 저장이고 메모리에 값쓰는게 100클럭 사이클이면 1 + 0.1 * 100 = 11이다.  
    - 위 같은 즉시쓰기의 해결방안은 쓰기버퍼를 활용하는 것이다.  
    쓰기버퍼는 데이터가 메모리에 쓰여질때까지 보관하기에 프로세서에선 메모리에 쓰이기를 기다리지 않고 처리가능 쓰기 버퍼가 가득 찰때만 지연된다.  
- 즉시쓰기의 대안으로 *나중쓰기(write-back)*도 있다.  
쓰기 데이터가 적중하면 캐시의 블록만 업데이트하면 된다. 각 블록값이 바뀌었는지 트래킹한다. 해당 블록이 다른 블록으로 교체될 때 바뀐 값으로 메모리를 업데이트  
이 방식이 더욱 효과적이지만 즉시쓰기 방식보다 실제구현은 더 복잡하다.  

### 쓰기에서의 캐시실패 처리
쓰기할당에선 블록을 캐시로불러오고 해당 워드만 덮어쓴다.  
쓰기비할당에선 메모리에 있는 블록 해당부분만 수정한다. 그냥 캐시에 안쓴다.  

### 캐시 성능  
CPU시간의 구성요소는 프로그램실행사이클,메모리지연클럭사이클이다.  
프로그램실행사이클엔 캐시적중시간(hit time)도 포함되고 메모리지연클럭사이클은 보통 캐시 실패때문에 주로 생긴다.  
CPU시간 = (프로그램실행사이클 + **메모리지연사이클**) * 클럭사이클시간
사실상 메모리지연사이클이 제일 크다.  
따로 분리해서 보면  
- 메모리지연사이클 = 읽기지연사이클 + 쓰기지연사이클 이다.  
읽기에 비해 쓰기지연은 쓰기버퍼지연도 추가해야하긴한데 너무 작아서 무시가능.  

읽기와 쓰기에 같은 실패율과 실패손실을 적용하면  
메모리지연클럭사이클 = (메모리접근횟수/프로그램) * 실패율 * 실패손실 = (명령어 수/프로그램) * (실패수/명령어수) * 실패손실  

CPI값이 주어지고(캐시 성공) I-cache의 실패율, D-cache의 실패율, 실패손실의 사이클, 적재&저장의 비율이 나타나져있으면  
명령어 별 실패 사이클 수를 계산할 수 있다.  
I-cache는 0.02 * 100 = 2 이고, D-cache는 0.36 * 0.04 * 100 = 1.44  
실제 CPI는 기본 성공 경우에 실패할 경우를 반영하여 다 더해야한다. 다라서 CPI = 2 + 2 + 1.44라 5.44이다. 이상적인 CPU는 실패가 발생 안하겠지..? 그러면 5.44/2 = 2.72배 만큼 빠를것이다.  

### 평균 접근 시간  
위에선 캐시성능을 지연시간 위주로 보았는데, 사실 적중시간(Hit time)도 아예 무시하면 안될거임. 중요한 부분임 나름!  
적중시간을 늘리는 주요인? => 캐시 크기의 증가  
**캐시크기가 크다**면 실패율이 내려가서 **지연시간 자체는 줄지만** 적중하기 위한 시간은 캐시 크기가 커진만큼 탐색을 넓게해야해서 **적중시간이 증가**한다.

그리하여 등장한... 평균접근시간 (AMAT;평균메모리접근시간)  
AMAT = 적중시간 + 실패율 * 실패손실  
예를들어 CPU가 적중시간이 1이고 실패손실이 20사이클. 캐시실패율이 5%라면  
AMAT = 1 + 0.05 * 20 = 명령어 별 2ns의 평균접근시간을 가진다.  

### 다른 캐시구조  
직접사상방식으로 살펴봤는데.. 실제론 블록을 배치하는 다양한 방식이 존재한다. 위에서 설명했던 완전연관방식, n-way집합연관캐시  
태그가 주소 전체를 나타내는 완전연관방식. 주어진 블록 있는지 찾으려면 캐시 내 모든 블록 검색해야하는데 **블록이 몇개 안되는 작은 캐시에만 사용가능하다**  
n-way집합연관캐시는 직접사상+완전연관. 각블록은 특정집합에만 들어갈 수있고 각 집합은 n개 엔트리 갖음. 따라서 블록 들어갈 수 있는 위치는 n개.  
어떤 집합에 들어갈지는 '메모리블록주소' modulo '집합'  
특정 아이템 찾이위해선 주어진 집합 n개 엔트리 검색해야한다.  
완전연관보단 비교가 적게 필요하다는 장점이 있다. n개엔트리비교  

예시를 보면..  
2-way 집합연관에서는 Cache Index값으로 n개의 집합중 하나를 택하고 그곳에 Blockadress를 넣는다. 있는대로 다 넣는데 만약 있으면 Hit인거고 값이 꽉차서 새로 들어가기 어려우면 사용한지 가장 오래된 블록을 교체하여 넣어준다.  
완전연관은 그냥 새로운거 들어오면 새로 넣어준다.  

n-way는 집합내에 몇개의 block을 넣을지 정하는 n이다.  
연관도가 증가할때 실패율은 낮아지는데 but 정도가 수렴  

**교체 블록 선택**  
직접사상은 어차피 하나라 선택할 필요가 없고,  
집합연관이나 완전연관은 가장 오랫동안 활용되지않은 블록을 교체하는 방법을 택한다 (Least-recently used; LRU) 하지만 각 블록별로 히스토리를 추적해야해서 연관정도가 커지면 복잡함.  

랜덤기법 - 높은 연관도 갖을때 LRU와 비슷한 성능을 보임  

**다단계 캐시**  
L1, L2로 나뉘어서 하는 캐싱. 대부분 컴퓨터가 활용하는 방법이고 프로세서와 같은 칩에 있다.  
L1캐시는 작지만 빠르고 L2캐시는 L1에서 실패발생하면 접근하는데 크고 느리지만 메인메모리보단 빠르다.  
만약 3차캐시가존재하면 L2에서 실패되면 3차로갈거임  

만약 L1만 있으면 CPI=1이고 클럭시간0.25ns이고 실패율 0.02이고 메모리접근 100ns라면  
실패손실 = 100ns/0.25ns = 400사이클  
실제 CPI = 1+0.02 * 400 = 9  

L2까지 있다면 접근시간이 5ns이고 메인메모리로 가는 실패율 = 0.5% = 0.005  
L2 적중시에 손실 = 5ns/0.25ns = 20사이클  
L2 실패까지 고려하면 CPI는...(L2접근시간까지 손실로 들감)  
CPI = 1 + 0.02 * 20 + 0.005 * 400 = 3.4  
따라서 L1만 쓸때는 9이고 L2까지 쓰면 3.4로 성능이 2.6배 차이가 난다.  