# 기계학습 11주차 강의  
실제상황에서는직관으로 특징선택을 하는것이 어렵다.  
어느것이 동일함을 가르키는지 일반적인 데이터로는 어렵기에 이를 해결하기 위한 효과적인 알고리즘이 필요하다.  
알고리즘을 통해 특징을 잘 선택할 수 있다.  
F={x1,x2,x3,x4}가 있으면 x1, x2, x3, x4, x1과x2, x1과x3, x1과x4, x2와x3, x3와x4, x3와x4, x1과x2와x3, x1과x2와x4, x1과x3와x4, x2와x3와x4, x1과x2와x3와x4  
이렇게 15가지가 생긴다. (2^4-1 = 15)  
이모든 부분집합에서의 점수를 각각 매겨서 가장 점수가 높은 점수를 갖는 부분집합을 선택하는 것이다.  

부분집합 하나당 1/1000초가 걸린다 가정해도, d(차원)에 따라서 특징 선택 시간의 추정이 어마어마하게 커지는데, 10차원일때 1초 걸렸던 것도 50차원일때는 35700년이 걸리게 된다.  
따라서 우리는 효율적 알고리즘을 찾아야한다.  

임의탐색 알고리즘이라는것도 있다. 아무생각 없이 여기저기 탐색.  
현재 시간 t=0이 최대시간으로 지정한 시간보다 작을때 계속 while문을 돌며 부분집합을 택하고 점수를 측정하고, 기존 score보다 크면 업데이트 하고 현재시간을 측정하고... 이런 방식  
J(x1), J(x2), J(x3), J(x4) 이 중 가장 큰 score를 갖는 2개를 선택.  
x1이 40, x2가 50, x3가 10, x4가 60점을 갖게된다면, x2와x4가 선택될 것이다.  
만약 세개를 택한다면 x1,x2,x4를 택하겠지..  
<b>이것이 개별특징평가 알고리즘이다.</b>  
간단하지만 특징들간 상관관계를 고려하지 않았기에 개별적으로는 점수가 낮지만 시너지 효과로 더 높은 점수를 갖는 조합을 알 수 없다.  
또한 중복성을 갖더라도 각각 특징이 점수가 높다는 이유로 선택이 될텐데.. 이 경우엔 원래 특징선택의 목적인 '중복성 제거'에 반하는 알고리즘이 될 수 있다.  
그래도 간단히 사용하기 쉬운 알고리즘! (특징들의 상관관계가 없을수록, 중복이 없을수록 좋은 알고리즘이 될듯..?) 특징들의 상관관계 크더라도 어느정도 보완은 되는 알고리즘임. 가장 치명적인건 중복을 제거못하는것이라 생각하면 될듯.  
J({x2,x4}) vs J({x1,x2,x4})?  

<b>전역 탐색 알고리즘</b>  
전체특징공간에서 '가능성 있는' 모든 영역을 탐색하는것이다.  
가능성 여부를 따지지않고 모두 탐색하는 것이 '낱낱 탐색 알고리즘'이다.  
탐색 도중 가능성 없다고 판단되는 영역을 배제하여 효율 높이는것은 '한정 분기 알고리즘'  
전역탐색알고리즘은 항상 '전역 최적해'를 보장한다.  
하지만 차원이 커질수록 현실적인 시간 내에 해를 구하지 못한다는 한계.....  

낱낱탐색알고리즘은 그냥 모든해를 다 살피는 알고리즘이고, 모든 차원에 대한 경우의수를 만들고 그 경우의수에 모든 점수를 구하여 최대 점수를 구한다.  

한정분기 알고리즘 원리 : 보통 차원수가 낮아질수록 점수가 낮아지는데, 2차원인 분기의 점수보다 3차원에서 점수가 더 낮다? 그 3차원 밑의 분기로는 갈 이유가 없다.  
이미 탐색했던 분기에서의 2차원 중에서의 최대점수보다는 최소한 더 높은 점수를 갖는 3차원을 탐색해야한다는 생각!  

낱낱에서는 4차원의 경우에서 12개 -> 6개의 점수값이 나왔는데,  
한정분기에서는 11개이다. 탐색과정중 가능성 없는 영역을 배제하지만, 어떠한 환경에서는 더 복잡한 계산환경을 갖게될 수도 있다는 것이다.  

### 순차탐색 알고리즘  
F=F1UF2 F1hF2 = o/  
SFS알고리즘 : 한번에 하나씩 특징을 추가해 나가는 방식  
하나씩 벡터가 추가되는 방식  
점점 점수가 올라가..?  
특징 하나에서 가장 점수가 높은것 선택.. 거기에서 추가로 붙는 특징벡터에서 가장 점수 높은것 선택.. 거기에서 추가로 붙는 특징벡터에서 가장 점수높은것 선택... 이러는데 더이상 더 점수가 높아지는곳이 없다? 그러면 현재에서 스탑  

PTA알고리즘 : p개의 특징을 추가하고 q개를 제거하는 연산을 반복  
증가하는건 알겠음. 근데 왜 제거?  
00000에서 00001, 00010, 00100, 01000, 10000 들 중.. 점수 가장 높은것 택  
ex) 01000이 젤높음. 선택. 01000에서 붙을수있는 특징 => 01001, 01010, 01100, 11000 들 중 젤 높은것... 01010이 젤 높아서 택했음. 01010에서 붙을수있는 특징 => 01110, 01011, 11010 중에 11010이 젤 높음. 그렇게 택했는데 뒤를 봤더니 11010으로 올수있는 애들 중, 01010보다 10010이 더 높은점수를 갖고있었음! => 그쪽으로 이동 전환..  

일반적 순차탐색 알고리즘은 지역 최적해, 전역최적해가 있으면 전역최적해로 갈 방법없이 지역최적해로 향하게 된다.  
하지만 PTA를 사용하면 전역 최적해도 찾아갈 수 있게 된다. (그럴 가능성을 높여줌)  

언제나 우수한 해로 이동하는것이 아니라, 열등한 해로 이동도 함으로써 다양한 형태 (담금질기법) 나타난다. 시뮬레이티드 어닐링  

유전알고리즘 : 자식해가 꼭 좋은쪽으로 이동하는것이 아님. 임의의 해들을 이곳저곳 가는데 그곳들 중에 더 좋은 성능을 갖는 해쪽으로 향한다. 다시 한번 알고리즘이 돌아감.. 그렇게 유전적으로 좀더 성능이 좋아지도록 향하는것. 뒤로 돌아가기도하고 최적으로 가기도하고.. 여러탐색을 한다.  

11주차 예제..  
7개의 샘플이 주어질때 python을 이용한 PCA기법으로 최적의 변환 축 구하기.  

