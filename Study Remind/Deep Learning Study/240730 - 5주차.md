## 6장. 학습 관련 기술들
> # 신경망 학습의 핵심 개념
> - 가중치 매개변수 최적값 탐색하는 최적화 방법
> - 가중치 매개변수 초깃값, 하이퍼파라미터 설정 방법 등
>
>오버피팅 대응책 : 가중치 감소, 드롭아웃 등의 정규화 방법

#### 매개변수 갱신
신경망의 목적은 손실함수 값을 가능한 낮추는 매개변수(가중치, 편향)를 찾는 것. 이러한 문제를 **최적화**라고 한다. 신경망에서의 최적화는 어렵다. 왜냐면 매개변수 수가 엄청나게 많기 때문이다. 심층 신경망은 더욱 어렵다.
 
지금까지는 최적의 매개변수를 기울기(미분)을 통해 구했고, 기울어진 방향으로 매개변수를 갱신하는 일을 반복하는 **확률적 경사 하강법(SGD)** 을 했었다. 문제에 따라 이보다 똑똑한 방법도 있다.
확률적 경사 하강법의 단점이 무엇인지, 그에 따른 다른 최적화 방법은 무엇이 있는지 알 수 있다.

눈을 감고 가장 깊은 곳에 걸어들어가야 한다면, 우리는 바닥의 경사를 통해 더욱 안쪽 길로 들어가는 일을 반복할 것이다.
#### 확률적 경사 하강법 (SGD)
확률적 경사 하강법 (SGD) 의 수식이다.
$W <= W - l*dL/dW$
W는 갱신할 가중치 매개변수, dL/dW는 W에 대한 손실함수 기울기. l은 학습률을 의미한다. (학습률은 0.01이나 0.001과 같은 값을 미리 정의함) <=는 우변값을 좌변에 대입한다는 것.
이러한 수식은 그저 기울어진 방향으로 일정 거리만큼만 W를 이동시키겠다는 단순한 방법이다.

> dL/dW는 손실값의 미분이 0에 가까워지고 있는지 멀어지고 있는지를 알 수 있다. 접선의 기울기가 양수라면 기울기가 0이 되기 위해서는 W값을 감소해야 하기에 -l * dL/dW = 음의 방향으로 조정하게 된다. 또한 접선 기울기가 음수라면 기울기가 0이 되기 위해서는 W를 증가시켜야 하기에 -l * dL/dW = -l * (음수) = 양의 방향으로 조정하게 된다.

```
def __init__(self, lr=0.01):
	self.lr = lr
def update(self, params, grads):
	for key in params.keys():
		params[key] -= self.lr * grads[key]
```
파이썬으로 이와 같이 구현할 수 있는데, W파라미터를 $W=W-1*lr*기울기$  로 구하는 것이다.
이러한 SGD같은 것을 Optimizer(최적화를 진행하는자)라고 할 수 있다.
##### SGD 단점
구현 쉽고 단순하지만, 문제에 따라 비효율적일 때 존재한다. $f(x,y)=1/20*x^2+y^2$ 라는 수식이 있다면, 이는 길게 늘린 밥그릇과 같은 모양이 된다.
이러한 식에 SGD를 적용하면 최솟값인 0, 0까지 지그재그로 계속 탐색하게 된다. 비효율적이다.
이렇게 SGD는 **비등방성 함수 (방향에 따라 성질, 기울기가 달라지는 함수)** 에서는 탐색 경로가 비효율적이게 된다. 이 경우 무작정 기울어진 방향으로 가는 방식은 좋은 해결책이 되지 못한다.
기울어진 방향이 본래의 최솟값을 가르키지 않는다는 이유도 있다.
=> 이를 개선해주는 방법 : **모멘텀, AdaGrad, Adam**
#### 모멘텀 (Momentum)
운동량을 뜻하는 단어. 물리와 연관되어있음.
$v <= av - l*dL/dW$
$W<=W+v$
W라는 갱신할 매개변수를 v라는 것을 활용해 갱신한다. a는 0.9와 같은 값으로 설정하고, av는 물체가 아무런 힘 안받을 때 서서히 하강시키는 역할, 물리에서 지면마찰, 공기저항을 뜻한다. v는 물체의 속도.

모멘텀을 활용하면 SGD처럼 지그재그로 문제 해답에 도착하는 것이 아닌, 공이 바닥을 구르듯 움직인다. 전체적으로는 SGD보다 x축 방향으로 빠르게 다가가기에 지그재그 움직임이 줄어든다.
#### AdaGrad
신경망 학습에선 학습률이 중요하다. 너무 작으면 학습이 길어지고 너무 크면 학습이 제대로 안된다.
학습률을 정하는 효과적인 기술로 **학습률 감소(Learning Rate Decay)** 가 있다. 학습 진행할 수록 학습률을 점차 감소시키는 방법이다. 실제 신경망 학습에 자주 쓰인다.
이러한 원리를 발전시킨 것이 AdaGrad이다. '각각' 매개변수에 맞춤형인 값을 만든다.
AdaGrad는 적응적으로 학습률을 조정하며 학습을 진행한다.
$h<=h+dL/dW(*)dL/dW$  ( * )는 원소별 곱셈
$W<=W-l\frac{1}{\sqrt{h}}\frac{dL}{dW}$
기존 기울기 값을 제곱하여 계속 더해주는 방식으로 h를 갱신한다. 그리고 이러한 h를 루트로 감싸서 W값에 적용하는 l값을 점차 감소시킨다.
AdaGrad를 파이썬으로 구현할 때는 가장 중요한 것이 바로 나누기하는 1/루트h 에서 h값이 너무 작아질수있기에 +1e-7을하여 0으로 나누어지는것을 방지하는 것이다.

> 가장 기초적인 원리는 결국 W = W - l* dL/dW 이다. 여기의 변형이 계속 이루어지는것.

(계속 제곱하여 더해가는 h값이기에, 학습 진행할수록 갱신 강도가 약해지고, 어느순간 갱신량은 0이되어 갱신하지 않게된다. 이 문제를 개선한 RMSProp이라는 방법도 있다. 먼 과거의 기울기를 잊고 새로운 기울기 정도를 크게 반영하는 방법인데, 지수이동평균이라하여 과거 기울기 반영 규모를 기하급수적으로 감소시키는 방법.)

AdaGrad는 실제로 결과를 보면 최솟값을 향해 매우 효율적이게 움직이는 모습을 볼 수 있다. 
#### Adam
모멘텀은 공구르기, AdaGrad는 원소마다 갱신 정도를 조정. 이 두가지를 융합한 AdaGrad+Momentum 이것이 바로 Adam이다.
굴러가면서 갱신정도를 적응적으로 조정하는 것. 또한 하이퍼파라미터의 편향보정도 들어간다.

SGD, 모멘텀, AdaGrad, Adam 네 가지를 알아보았는데, 어느 하나 정답이라는 것은 없다.
각자 잘 해결하는 문제, 잘 해결하지 못하는 문제가 있을 뿐이다. 아직도 많은 연구에서 SGD를 사용하고 있고, Adam을 요즘에는 많이 사용한다. 각자 상황을 고려하여 쓰는 것이다.
### MNIST로 비교한 갱신 방법들
SGD, 모멘텀, AdaGrad, Adam 중에서 MNIST에 가장 효과가 안좋은 것은 SGD였고, 나머지 세개는 비슷하지만 근소하게 AdaGrad가 성능이 더 좋았다. 다만, 이 경우는 각 층이 100개 뉴런으로 구성된 5층 신경망에서 ReLU를 사용했을 때의 일이다. 이러한 하이퍼파라미터(학습률, 신경망 층 깊이 등)에 따라 결과가 달라지는 것을 명심. => 그래도 알 수 있는것은 SGD보단 다른 3개가 더 빠르고 정확하다.
### 가중치 초깃값
가중치의 초깃값을 무엇으로 하느냐도 중요하다. 권장 초깃값은 무엇일까
초깃값을 모두 0으로 설정하면? => **나쁜 아이디어**이다. 올바른 학습이 진행되지 않음.

오차역전파법에서 모든 가중치 값이 똑같이 갱신되기에 문제가 된다. 가중치를 여러개 갖는 의미가 사라진다. 초깃값은 그래서 무작위로 설정해야 한다.
##### 시그모이드 에서의 가중치 초깃값
가중치 표준편차를 1로 해도 문제가 발생한다.
시그모이드를 사용한 경우를 예로 들면, 출력이 0혹은1에 가까워지자 미분이 0에 다가간다. 그래서 역전파 기울기 값이 점점 작아지다 사라진다. 이것이 **기울기 소실** 문제이다. 층이 깊은 딥러닝에서는 기울기 소실이 더욱 큰 문제가 된다.

가중치 표준편차를 0.01로 바꿔 실험을 반복한다면? 이번에는 0.5 정도로 집중된다. 0과 1에 치우쳐지지는 않아 기울기 소실문제는 일어나지 않았다. 하지만 활성화값이 치우쳐진것이 문제이다. 다수 뉴런이 거의 같은 값을 표현한다면, 여러개를 둔 의미가 없다. 이렇게 **너무 작은 표준편차는 표현력을 제한한다**는 문제를 갖는다.

권장 가중치 초깃값이 있다. 일명 **Xavier 초깃값**이다. 활성화함수가 선형인 것이 전제일 때 초깃값의 표준편차가 $\frac{1}{\sqrt{n}}$인 분포를 사용하는 것이다. (sigmoid나 tanh함수는 좌우대칭이라 중앙부근이 선형인 함수로 볼 수 있음) 이를 활용해보니 넓게 분포되는 것을 볼 수 있다.
##### ReLU에서의 가중치 초깃값
ReLU에 특화된 초깃값은 카이밍 히의 이름을 따 **He 초깃값**이라고 부른다. 앞 계층 노드가 n개일 때 표중편차가 $\sqrt{\frac{2}{n}}$ 인 정규분포를 사용한다. 실제로 ReLU의 표준편차값이 0.01, Xavier값, He값을 적용해보면 0.01의 경우는 학습이 거의 이루어지지않고, Xavier은 층이 깊어지면서 문제가 생기고, He초깃값은 모든 층에서 층이 깊어져도 분포가 균일하게 유지된다.

> [!중요]
> 초기 표준편차값을 Sigmoid는 Xavier값, ReLU는 He값을 사용한다. 이것이 현재 모범사례이다.

### 배치 정규화
각 층이 활성화를 적당히 퍼트리도록 강제할 수 있나? **배치 정규화**(Batch Nomalization) 로 가능하다. 배치 정규화는 세상에 나온지 얼마 안된 (2015) 기법인데도 많이 사용하고 있다. 뛰어난 결과 달성한 예시가 많다.

**배치 정규화가 주목받는 이유**
1) 학습 속도 개선
2) 초깃값에 크게 의존하지 않음
3) 오버피팅을 억제 (드롭아웃 등 필요성 감소)

배치 정규화라는 계층을 Affine 계층과 ReLU계층 사이사이에 넣어준다. 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화 한다. (학습 시 미니배치를 단위로 정규화 해주는 것)
$\mu_B \leftarrow \frac{1}{m}\sum_{i=1}^{m}x_i$ 
$\sigma_B^2 \leftarrow \frac{1}{m}\sum_{i=1}^{m}(x_i-\mu_B)^2$
$\hat{x_i} \leftarrow \frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}$
미니배치 B라는 x1,x2,...,xm m개의 입력데이터 집합에 대한 평균과 분산을 구한다. 그리고 입력 데이터를 평균은 0, 분산은 1이 되도록 정규화한다. $\epsilon$기호는 작은값(10e-7)같이 0으로 나누는사태를 방지하기 위한 값임

그냥 위 식은 단순히 미니배치 입력데이터 B를 평균0, 분산1인 데이터들로 변환하는 일을 한다. 이러한 처리는 활성화 함수의 앞(혹은뒤)에 삽입하여 데이터 분포가 덜 치우쳐지도록 할 수 있다.
배치 정규화 계층마다 고유하게 확대(scale), 이동(shift)변환 수행한다.
$y_i \leftarrow \gamma\hat{x_i}+\beta$
감마가 확대, 베타가 이동을 담당. 두값은 초기엔 감마=1, 베타=0으로 시작하여 학습하며 적합한값으로 조정해감.

배치정규화의 역전파도 계층그래프로 그린 후, 따로 구할 수 있음.
**거의 모든 경우에서 배치정규화를 사용한 경우가** 사용하지 않은 경우보다 **학습 진도가 빠른** 것을 볼 수 있다. 
### 바른 학습.
**과적합 (오버피팅)** 되는 일이 기계학습에서는 잦다. 훈련 데이터에 지나치게 적응되어 그 외 데이터에는 제대로 대응하지 못하는 상태를 뜻한다.
오버피팅을 억제하는 기술이 중요하다.
#### 오버피팅 (과적합)
주로 두 경우에 일어난다.
1) 매개변수가 많고 표현력이 높은 모델
2) 훈련 데이터가 적은 경우
> 만약 훈련데이터의 경우가 시험 데이터보다 너무 높은 정확도를 보이면 그것이 바로 과적합이다. 사실 훈련데이터와 시험데이터는 단지 똑같은 데이터들을 일정 수 만큼 분리한것 뿐이기에 둘은 비슷한 정확도가 나타나야 한다.
#### 가중치 감소배치 정규화 계층마다 고유하게 확대(scale), 이동(shift)변환 수행한다.

감마가 확대, 베타가 이동을 담당. 두값은 초기엔 감마=1, 베타=0으로 시작하여 학습하며 적합한값으로 조정해감.

배치정규화의 역전파도 계층그래프로 그린 후, 따로 구할 수 있음.
거의 모든 경우에서 배치정규화를 사용한 경우가 사용하지 않은 경우보다 학습 진도가 빠른 것을 볼 수 있다. 
바른 학습.
과적합 (오버피팅) 되는 일이 기계학습에서는 잦다. 훈련 데이터에 지나치게 적응되어 그 외 데이터에는 제대로 대응하지 못하는 상태를 뜻한다.
오버피팅을 억제하는 기술이 중요하다.
오버피팅 (과적합)
주로 두 경우에 일어난다.
1) 매개변수가 많고 표현력이 높은 모델
2) 훈련 데이터가 적은 경우
> 만약 훈련데이터의 경우가 시험 데이터보다 너무 높은 정확도를 보이면 그것이 바로 과적합이다. 사실 훈련데이터와 시험데이터는 단지 똑같은 데이터들을 일정 수 만큼 분리한것 뿐이기에 둘은 비슷한 정확도가 나타나야 한다.
#### 가중치 감소
오버피팅 억제용으로 많이 사용한 방법이다. 학습 과정에서 큰 가중치에 대해선 그만큼 큰 패널티를 주는 방법이다. **오버피팅은 원래 가중치매개변수의 값이 너무커서 발생하는 경우가 많기때문이다.**
신경망 학습 목적은 손실함수 값 줄이는 것. 예를 들어 가중치의 제곱 놈(L2 놈)을 손실함수에 더한다. 그러면 가중치가 클수록 손실함수가 커지기에 가중치가 커지는 것을 억제한다.

가중치가 W이면 L2놈에 따른 가중치감소는 $\frac{1}{2}\lambda W^2$ 이고 이걸 손실함수에 더한다. 람다는 정규화 세기를 조절하는 하이퍼파라미터이다. 람다가 크게 설정될수록 큰 가중치에 대한 패널티도 커진다.
1/2를 둔 이유는 W기준으로 미분했을 때 딱 떨어져서 $\lambda W$ 가 될 수 있도록 하기 위함임.

가중치 감소과정에서 모든 가중치 각각 손실함수에 $\frac{1}{2}\lambda W^2$ 를 더하게되고, 오차역전파 결과에 미분한 $\lambda W$ 을 더하면 된다.(정규화 항의 미분)
결과에서 여전히 차이는 발생하지만 L2놈 가중치감소를 적용하지 않은 경우보다는 오버피팅이 억제된다.
#### 드롭아웃
L2놈을 더한 가중치 감소 방법은 간단구현이 가능하고, 어느정도는 과적합방지가 가능하다. 하지만 **모델이 복잡해지면** 가중치 감소만으로는 대응 어렵다. 그래서 **드롭아웃(Dropout)** 이라는 기법을 흔히 이용한다.
> [!드롭아웃이란]
> 뉴런을 임의로 삭제하며 학습하는 방법. 훈련 때 은닉층의 뉴런을 무작위로 골라 삭제한다.

훈련 때 무작위로 뉴런을 골라 삭제하고, 삭제된 뉴런은 신호전달하지 못하게 된다. **훈련 때만 삭제할 뉴런을 무작위로 선택하고, 시험 때는 모든 뉴런에 신호를 전달한다.** 시험 때는 각 뉴런 출력에 훈련 때 삭제안한 비율을 곱해서 출력한다.

파이썬 코드로 보면, 순전파때마다 self.mask에 삭제할 뉴런을 False로 표시한다. (무작위)
드롭아웃 된 훈련으로 결과를 뽑아보면 **훈련 데이터와 시험 데이터**에 대한 정확도 차이가 줄어든다. 또한 훈련 데이터에 대한 정확도가 과적합 (100%에 도달)하지 않을 수 있게 되었다.
**드롭아웃을 통해 표현력을 높이면서도 오버피팅(과적합)을 억제할 수 있었다**

(기계 학습에선 앙상블 학습을 애용함. 개별적으로 학습한 여러 모델 출력을 평균내어 추론하는 방식. 드롭아웃은 하나의 네트워크로 앙상블 학습효과를 낸것이라고 생각가능)
### 적절 파라미터 값 찾기
각 층 뉴런 수, 배치 크기, 매개변수 갱신 시의 학습률, 가중치 감소 등 하이퍼파라미터 값 설정이 중요하다. 하지만 이 값 결정에는 많은 시행착오를 겪게 된다. 어떻게 효율적으로 탐색이 가능?

>[!주의]
> 하이퍼파라미터 성능 평가할 때는 시험 데이터 사용하면 안된다.

시험 데이터로 하이퍼파라미터 조정하면 하이퍼파라미터 값이 **시험 데이터에 오버피팅(과적합) 되기 때문**이다. 범용성을 위해서라도 이러면 안됨.
=> 따라서 하이퍼파라미터 조정 시엔 하이퍼파라미터 전용 확인데이터가 필요. 이러한 조정용 데이터를 **검증 데이터 (Validation data)** 라고 부른다.

훈련 데이터 : 매개변수 학습
검증 데이터 : 하이퍼파라미터 성능 평가
시험 데이터 : 신경망의 범용 성능 평가

데이터셋에 따라 이 세개를 미리 분리해둔 경우도 있지만, 분리가 안되어있거나, 훈련/시험으로만 분리된 경우엔 사용자가 직접 분리해야한다.
보통 '훈련 데이터' 중 20% 정도를 검증 데이터로 분리한다.
혹시 데이터가 정렬되어 있을 수 있기에 shuffle_dataset이라는 메소드로 섞을수도 있다.
#### 하이퍼파라미터 최적화
하이퍼파라미터 최적화의 핵심은 **'최적 값' 존재하는 범위를 조금씩 줄여나가는 것이다.** 조금씩 범위 줄이려면 우선 대략적 범위 설정 후 그 범위에서 무작위로 샘플링(값 골라내기) 후 정확도를 평가한다. 이런 작업을 반복하며 최적의 하이퍼파라미터 값 범위를 좁혀나가는 것이다.

이런 범위는 **대략적**으로 정하는것이 효과적. 0.001에서 1000 사이 (10의 거듭제곱 단위)로 범위를 지정한다. 로그 스케일(log scale)로 지정한다고도 말함.

하이퍼파라미터 최적화는 딥러닝의 경우 오랜시간(며칠, 몇 주) 걸린다. 학습을 위한 에폭을 작게해서 1회 평가에 걸리는 시간을 단축하는것이 효과적이다.

**하이퍼 파라미터 최적화의 단계**
0) 하이퍼파라미터 값 범위 설정
1) 설정 범위에서 하이퍼파라미터 값 무작위로 추출
2) 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도 평가. (단, 에폭은 작게)
3) 1~2단계를 특정 횟수(100회 등) 반복하여 정확도 결과를 보고 하이퍼파라미터 범위를 좁힘

과학보단 약간 지혜와 직감이 중요한 느낌. 수학 이론으로 효율적인 최적화를 진행하는 **베이즈 최적화(Bayesian Optimization)** 이라는 것도 있다.

구현한다면 0.001 ~ 1000 부터 시작하여 학습률이 높은 쪽의 방향에서 범위를 좁혀서 또 진행..진행... 그랬더니 만약 0.001~0.01이 되고 가중치 감소계수도 10^-8~ 10^-6 정도로 되었다? 잘 된것이다. 이렇게 좁혀나가다가 특정 단계에서 하나의 하이퍼파라미터 값을 선택하면 된다.

### 마무리
- 매개변수 갱신 방법 : SGD 외에도 모멘컴, AdaGrad, Adam 등
- 가중치 초깃값 설정 방법 : Sigmoid는 Xavier 초깃값, ReLU는 He 초깃값
- 배치 정규화 : 학습 빠르게 진행 가능하며 초깃값에 영향 덜받음
- 드롭아웃 : 오버피팅(과적합)을 억제하기 위한 기법으로, 드롭아웃 말고도 가중치 감소가 있다.
- 하이퍼파라미터 값 탐색 : 최적값 존재할 법한 위치에서 범위를 점차 좁혀가며 샘플링하여 탐색