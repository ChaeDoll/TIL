## 8장 - 딥러닝

#### 더 깊은 신경망
CNN과 같은 신경망을 층을 깊게 한 '심층 신경망'을 우리는 딥러닝이라고 부른다.
층이 깊어지며 채널 수가 더욱 늘어나는 특징을 가진 심층 CNN을 봐본다면,
**(이게 혹시 VGG 신경망 생김새인가??)** 3x3의 작은 필터를 사용한 합성곱계층으로 채널수는 늘어나고 풀링 계층을 통해 공간크기는 점차 줄여진다. 그리고 마지막 Fully-Connected 계층에서는 드롭아웃을 적용한다. (드롭아웃이 뭐더라 간단하게 소개)
가중치 초깃값으로는 He 초깃값을 사용하고 **(값 알려주기)** 가중치 매개변수 갱신은 Adam을 이용한다. **(매개변수 갱신 그래프 그림 예시 보여주기)**

VGG라는 신경망의 특징이 결국 지금까지 배웠던 신경망 기술을 잔뜩 녹인 신경망이다. 이것으로 MNIST를 학습하면 99.38% 정도가 된다. **(아주 훌륭한 성능)**
잘못 인식된 경우를 뽑아내서 봐보면 사람도 구분하기 어렵다. **(사진 보여주며)** 즉, 판별을 잘하는, 성능이 좋은 예시라고 할 수 있다.
#### 정확도를 더욱 높이기
발표된 기법들의 정확도 순위를 보면, Neural Netwroks, Deep, Convolutional 이라는 키워드가 돋보인다. 상위권 대부분 CNN을 기초로 한 기법들이다.
2016년 10월 MNIST 데이터셋 정확도 1위는 99.79%인 기법인데 이것도 CNN을 기초로했다.
> 그러면 2024년 8월 현재는 어떨까? What is the class of the image 사이트에서 가져와서 보여주기

이런 상위 랭킹의 기법들을 참고하면 정확도를 올리는 기법이나 힌트를 얻을 수 있다.
그 중 **데이터확장 (Data Augmentation)** 기법이 있다. 입력 이미지 (훈련 이미지)를 알고리즘을 동원해서 인위적 확장을 수행하는 기법이다.
데이터를 회전시키거나, 이동시키거나.. 그 외에도 일부를 잘라내거나 좌우를 뒤집는 방법도 있다. 
> 이미지들 예시 보여주기.. 또다른 데이터 확장 기법은 무엇이 있을까???
> 혹은 이미지 말고도 자연어처리는 데이터확장을 어떻게 진행할까? 갑자기 궁금함! (멀티모달 등)

층을 그렇다면 왜 깊게하는 것이 중요할까?
1) **신경변수의 매개변수 수가 줄어든다.**  (깊은 신경망은 깊지 않은경우보다 적은 매개변수로 같은 표현력을 만들 수 있음) - 예를들어 5x5 합성곱 연산 1회대신, 3x3 합성곱 연산 2회로 바꾸어본다면, 똑같은 1x1의 결과를 만들면서 (즉, 대체가능) 5x5는 매개변수가 25개였지만, 3x3은 2번해서 3x3x2 = 18이라는 더 적은 매개변수를 가질수있다. 여기선 단순히 1개의 합성곱과 2개의 합성곱을 비교했는데, 이 개수 차이는 층 깊어질수록 커진다.
   
   역으로 생각해서 또 3x3 합성곱 연산을 3회 반복하면 매개변수는 27개가 되지만, 이만한 탐색을 1회로 마치려면 7x7, 49개 매개변수가 필요하다.
   (매개변수를 줄이면 수용영역을 소화할 수 있다. 신경망의 비선형 힘을 가한다. 이가 겹쳐지며 더욱 복잡한것도 표현가능하게 된다.)
2) **학습의 효율성을 좋게한다.** 층을 깊게하면 학습데이터 양을 줄기에 더 빠르게 학습수행이 가능하다. 앞에서 합성곱계층은 에지같은 단순패턴에 뉴런이 반응하고 층 깊어지며 텍스쳐와 사물의 일부 같은 더 복잡한것에 반응한다 하였다. 
   얕은 신경망에서 만약 개를 본다면 해결을 위해 **한번에** 특징의 대부분을 이해해야 한다. 견종, 찍은 각도 등 다양한 변화에 대한 학습데이터가 필요하고, 이로인해 학습시간도 오래걸린다.
   하지만 신경망을 깊게하면 마치 역할을 나누듯 학습해야할 문제를 계층적 분해할 수 있다.
   첫 층이 에지에 전념하기에 더욱 적은 학습데이터로 효율적 학습을 진행하고, 층이 깊어질수록 이렇게 얻은 정보들을 다시 다음 계층에 활용하며 점차 고도의 패턴학습을 할 수 있게 된다.
	> 층마다 역할로 첫번째는 에지 점차 깊어질수록... 복잡패턴을 해결! 이라는 그림또는 이미지
	
#### 딥러닝 초기 역사
딥러닝은 2012년 ILSVRC(이미지인식기술챌린지) 대회에서부터 주목받기 시작했다. 이 때 딥러닝이 주목받은 전환점이 되었다.
이미지넷은 100만장 넘는 이미지 데이터셋이고, ILSVRC는 이 거대 데이터셋을 활용해 자웅을 겨루는 대회이다. 
몇가지 시험 항목 중, **분류**가 그 중 하나이다. 제대로 1000개의 클래스를 분류하는지 겨룬다. 
성적추이를 보면 2012년 이후부터는 항상 딥러닝 방식이 선두를 맡고있다고한다. 실제로 2012년에 AlexNet이 압도적으로 오류율을 크게낮추며 성공한 이후, 딥러닝을 활용한 기법이 꾸준히 정확도를 개선해왔다.
2015년엔 150층 넘는 심층 신경망 ResNet이 top5 오류를 3.5%까지 줄였다. (인간의 인식을 넘어선다한다.)

뛰어난 성적 거두고있는 딥러닝 중에서도 VGG, GoogLeNet, ResNet이 유명하고 다양한 딥러닝 분야에서 활용된다. 
> 이젠 또 뭐가 있을까???

#### VGG
VGG는 3x3라는 작은 필터를 사용한 합성곱계층을 연속적으로 거치며 풀링 계층까지 넣으며 크기를 절반으로 둘이는 크기를 반복하고 최종적으로 완전연결 계층을 통과해 결과를 출력한다.
구성이 간단하여 응용하게 좋다. (이미지 보여주기) 
> 어느 분야에 주로 활용되는지 (이미지 중) 예시 보여주기.
#### GoogLeNet
이미지와 함꼐..
구성이 매우 복잡해보이는데, 세로 깊이뿐만 아닌 가로깊이도 깊은 특징을 가진다. 1x1, 3x3, 5x5의 합성곱과 3x3의 최대풀링을 모두 계산 후 필터결합하여 활용한다. 이러한 가로깊이가 있는 구조를 하나의 구성요소로 활용한다.
Googl