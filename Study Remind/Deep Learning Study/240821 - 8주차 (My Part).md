## 8장 - 딥러닝

#### 더 깊은 신경망
CNN과 같은 신경망을 층을 깊게 한 '심층 신경망'을 우리는 딥러닝이라고 부른다.
층이 깊어지며 채널 수가 더욱 늘어나는 특징을 가진 심층 CNN을 봐본다면,
**(이게 혹시 VGG 신경망 생김새인가??)** 3x3의 작은 필터를 사용한 합성곱계층으로 채널수는 늘어나고 풀링 계층을 통해 공간크기는 점차 줄여진다. 그리고 마지막 Fully-Connected 계층에서는 드롭아웃을 적용한다. (드롭아웃이 뭐더라 간단하게 소개)
가중치 초깃값으로는 He 초깃값을 사용하고 **(값 알려주기)** 가중치 매개변수 갱신은 Adam을 이용한다. **(매개변수 갱신 그래프 그림 예시 보여주기)**

VGG라는 신경망의 특징이 결국 지금까지 배웠던 신경망 기술을 잔뜩 녹인 신경망이다. 이것으로 MNIST를 학습하면 99.38% 정도가 된다. **(아주 훌륭한 성능)**
잘못 인식된 경우를 뽑아내서 봐보면 사람도 구분하기 어렵다. **(사진 보여주며)** 즉, 판별을 잘하는, 성능이 좋은 예시라고 할 수 있다.
#### 정확도를 더욱 높이기
발표된 기법들의 정확도 순위를 보면, Neural Netwroks, Deep, Convolutional 이라는 키워드가 돋보인다. 상위권 대부분 CNN을 기초로 한 기법들이다.
2016년 10월 MNIST 데이터셋 정확도 1위는 99.79%인 기법인데 이것도 CNN을 기초로했다.
> 그러면 2024년 8월 현재는 어떨까? What is the class of the image 사이트에서 가져와서 보여주기

이런 상위 랭킹의 기법들을 참고하면 정확도를 올리는 기법이나 힌트를 얻을 수 있다.
그 중 **데이터확장 (Data Augmentation)** 기법이 있다. 입력 이미지 (훈련 이미지)를 알고리즘을 동원해서 인위적 확장을 수행하는 기법이다.
데이터를 회전시키거나, 이동시키거나.. 그 외에도 일부를 잘라내거나 좌우를 뒤집는 방법도 있다. 
> 이미지들 예시 보여주기.. 또다른 데이터 확장 기법은 무엇이 있을까???
> 혹은 이미지 말고도 자연어처리는 데이터확장을 어떻게 진행할까? 갑자기 궁금함! (멀티모달 등)

층을 그렇다면 왜 깊게하는 것이 중요할까?
1) **신경변수의 매개변수 수가 줄어든다.**  (깊은 신경망은 깊지 않은경우보다 적은 매개변수로 같은 표현력을 만들 수 있음) - 예를들어 5x5 합성곱 연산 1회대신, 3x3 합성곱 연산 2회로 바꾸어본다면, 똑같은 1x1의 결과를 만들면서 (즉, 대체가능) 5x5는 매개변수가 25개였지만, 3x3은 2번해서 3x3x2 = 18이라는 더 적은 매개변수를 가질수있다. 여기선 단순히 1개의 합성곱과 2개의 합성곱을 비교했는데, 이 개수 차이는 층 깊어질수록 커진다.
   
   역으로 생각해서 또 3x3 합성곱 연산을 3회 반복하면 매개변수는 27개가 되지만, 이만한 탐색을 1회로 마치려면 7x7, 49개 매개변수가 필요하다.
   (매개변수를 줄이면 수용영역을 소화할 수 있다. 신경망의 비선형 힘을 가한다. 이가 겹쳐지며 더욱 복잡한것도 표현가능하게 된다.)
2) **학습의 효율성을 좋게한다.** 층을 깊게하면 학습데이터 양을 줄기에 더 빠르게 학습수행이 가능하다. 앞에서 합성곱계층은 에지같은 단순패턴에 뉴런이 반응하고 층 깊어지며 텍스쳐와 사물의 일부 같은 더 복잡한것에 반응한다 하였다. 
   얕은 신경망에서 만약 개를 본다면 해결을 위해 **한번에** 특징의 대부분을 이해해야 한다. 견종, 찍은 각도 등 다양한 변화에 대한 학습데이터가 필요하고, 이로인해 학습시간도 오래걸린다.
   하지만 신경망을 깊게하면 마치 역할을 나누듯 학습해야할 문제를 계층적 분해할 수 있다.
   첫 층이 에지에 전념하기에 더욱 적은 학습데이터로 효율적 학습을 진행하고, 층이 깊어질수록 이렇게 얻은 정보들을 다시 다음 계층에 활용하며 점차 고도의 패턴학습을 할 수 있게 된다.
	> 층마다 역할로 첫번째는 에지 점차 깊어질수록... 복잡패턴을 해결! 이라는 그림또는 이미지
	
#### 딥러닝 초기 역사
딥러닝은 2012년 ILSVRC(이미지인식기술챌린지) 대회에서부터 주목받기 시작했다. 이 때 딥러닝이 주목받은 전환점이 되었다.
이미지넷은 100만장 넘는 이미지 데이터셋이고, ILSVRC는 이 거대 데이터셋을 활용해 자웅을 겨루는 대회이다. 
몇가지 시험 항목 중, **분류**가 그 중 하나이다. 제대로 1000개의 클래스를 분류하는지 겨룬다. 
성적추이를 보면 2012년 이후부터는 항상 딥러닝 방식이 선두를 맡고있다고한다. 실제로 2012년에 AlexNet이 압도적으로 오류율을 크게낮추며 성공한 이후, 딥러닝을 활용한 기법이 꾸준히 정확도를 개선해왔다.
2015년엔 150층 넘는 심층 신경망 ResNet이 top5 오류를 3.5%까지 줄였다. (인간의 인식을 넘어선다한다.)

뛰어난 성적 거두고있는 딥러닝 중에서도 VGG, GoogLeNet, ResNet이 유명하고 다양한 딥러닝 분야에서 활용된다. 
> 이젠 또 뭐가 있을까???

#### VGG
VGG는 3x3라는 작은 필터를 사용한 합성곱계층을 연속적으로 거치며 풀링 계층까지 넣으며 크기를 절반으로 둘이는 크기를 반복하고 최종적으로 완전연결 계층을 통과해 결과를 출력한다.
구성이 간단하여 응용하게 좋다. (이미지 보여주기) 
> 어느 분야에 주로 활용되는지 (이미지 중) 예시 보여주기. 혹시 얘가 빠르다면?그럼 실시간 감지에 활용되려나?
#### GoogLeNet
이미지와 함꼐..
구성이 매우 복잡해보이는데, 세로 깊이뿐만 아닌 가로깊이도 깊은 특징을 가진다. 1x1, 3x3, 5x5의 합성곱과 3x3의 최대풀링을 모두 계산 후 필터결합하여 활용한다. 이러한 가로깊이가 있는 구조를 하나의 구성요소로 활용한다.
GoogLeNet에서는 1x1필터도 사용하는데, 이는 채널쪽으로 크기를 줄이는 것으로 매개변수 제거와 고속처리에 기여한다. 
#### ResNet
Residual Network는 마이크로소프트의 팀이 개발한 네트워크이고, 지금까지보다 층을 더 깊게 할 수 있는 특별한'장치'에 있다.
지금까지 층이 깊을수록 성능이 좋아진다했지만, 딥러닝학습에서 지나치게 층이 깊을때 오히려 성능이 떨어지는 경우도 많은 것을 알 수 있다. (예를 들면 가중치 소실 문제)
이런 문제를 ResNet은 **스킵연결(skip connection)** 을 통해 해결한다. 
이 방법은 가중치계산후ReLU=>가중치계산후ReLU=> 라는 두개의 합성곱계층 과정을 건너뛰어 그대로 이전 x를 이후 x로 전달하는 스킵연산을 추가하는 것이다.
이렇게 되면 2개의 합성곱계층을 거친 출력 + 거치기전의 입력x 가 된다. 이 x덕에 신호감쇠, 즉 가중치 소실문제를 줄여주는 것이다.
ResNet은 VGG신경망을 기반으로 스킵연결을 도입하여 층을 깊게한 것이다.
실험 결과 150층이라는 막대한 층을 거쳐도 정확도가 오르는것을 볼 수 있었다.
**imageNet은 실제 제품에 활용해도 좋다. 이를 전이학습이라 하는데, 이미 학습된 가중치를 다른 신경망에 복사하고 그 상태로 재학습 수행한다. VGG와 구성이 같은 신경망 구성하고 가중치를 초깃값으로 한뒤 새로운 데이터셋을 대상으로 파인튜닝하여 사용할 수 있는것. 보유 데이터셋 적을때 유용하다.**
#### 더 빠른 딥러닝(딥러닝 고속화)
기본에는 CPU가 계산을 답당했는데 최근 딥러닝 프레임워크 대부분은 GPU를 이용해 대량연산을 고속처리 한다. 
AlexNet을 가져와서 어느층에서 가장 시간이 오래걸리나 보면, 대부분의 시간을 합성곱계층에서 보낸다. 처리 시간을 보면 CPU에서는 전체 89%, GPU에서는 전체 95%의 처리시간이 합성곱계층이라 한다. 따라서 합성곱계층의 연산을 어떻게 효율적으로 고속화하냐가 딥러닝의 과제이다.

GPU를 이용한 고속화라했는데, GPU는 원래 영상, 이미지 연산을 위한 그래픽 전용 보드에 이용해왔다. GPU는 복잡한 계산에 대한 능력은 낮지만, 병렬적인 연산이 가능한데, 딥러닝에서는 대량의 단일곱셈누산(또는 큰 행렬의 곱)을 수행해야하고, 단순한 연산을 대량으로 해야하는것에 이러한 GPU가 특화된 것이다. 그래서 CPU보다 빠른것이다. (CPU는 연속적이고 복잡한 계산처리를 잘함)
실제로 CPU에서 40일 걸리던것이 GPU에서 6일까지 단축되고, cuDNN이라는 엔비디아의 CUDA라는 GPU컴퓨팅용 통합개발환경에서 동작하는 라이브러리로 더욱 빠른 결과를 얻을수있다. (딥러닝에 최적화된 함수등이 구현되어있음)

**분산학습** : 딥러닝만으로도 물론 가속되었지만, 그래도 심층신경망의 학습에는 며칠 몇주처럼 오래걸린다. 딥러닝은 많은 시행착오가 필요한데 뛰어난 신경망 만들려고 오랜시간 시험을 반복해야하는 점을 보았을때 1회 학습 시간을 최댛나 줄이고 싶어질것이다.

다수 GPU와 기기로 계산을 분산하기도 한다. 구글텐서플로, 마이크로소프트CNTK(Computational Network Toolkit)은 분산학습에 역점 두고 개발중이다. 이런 대기업의 거대한 데이터센터에서 저지연,고처리량 네트워크를 활용한 분산학습이 놀라운 효과를 보이고있다. 
GPU가 늘어날수록 학습속도도 빨라지는데, 여러기기를 연결하여 GPU를 100개까지 사용하니 56배나 속도가 빨라져 7일의 과제를 3시간만에 해결하는것을 볼수있었다.
물론 계산을 어떻게 분산시키냐는 어려운 문제이고, 