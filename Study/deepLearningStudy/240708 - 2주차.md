### 4챕터 (107페이지부터 146페이지까지)

## 신경망 학습
신경망의 학습지표 : 손실 함수. **손실 함수를 최소로 만드는 가중치 parameter를 찾는 것이 학습의 목표.** 그를 위한 함수의 기울기 활용하는 경사법이 있다.
신경망은 데이터를 보고 학습이 가능하다. 학습이란.. 가중치 매개변수를 자동으로 결정하는 것이다. 수천, 수만, 수억개에 이르는 파라미터를 사람이 직접 결정하는것은 불가능한 일. MNIST 손글씨로 학습 코드를 구현한다.

퍼셉트론도 직선으로 분리가능하다면(선형 분리 문제) 데이터를 자동 학습 가능하다. 하지만 비선형 분리 문제는 자동 학습할 수 없다.

**데이터 주도 학습** (기계 학습 방식)
사람은 경험과 직관을 단서로 시행착오를 겪으며 일을 진행한다. 하지만 기계학습은 사람의 개입을 최소화하고 수집한 데이터 내에서 패턴을 찾는다. 신경망, 딥러닝은 기존 기계학습 방법보다 사람 개입을 더욱 배제할 수 있게 해주는 중요 특성을 지녔다.
> 기계학습보다 사람의 개입을 배제한다? 기계학습은 사람의 개입이 많았나보다?

이미지에서 **특징(feature)** 을 추출하고 그 특징패턴을 기계학습 기술로 학습하는 방법이 있다. 이미지의 특징을 벡터로 주로 기술한다. Computer Vision 분야는 **SIFT, SURT, HOG 등**의 특징을 많이 사용한다. 이러한 특징을 사용해 **이미지 데이터 => 벡터로 변환**하고, 벡터를 가지고 지도학습  한다. 대표적인 분류 기법으론 SVM, KNN 등이 있다.
> 이미지를 벡터로 전환하면 어떤 형태로 변환이 될까? 벡터라는 것은 배열로 전환되나? SIFT, SURT, HOG와 같은 특징을 사용하면 어떻게 변환이 될까?

기계학습 방식은 모아진 데이터에서 규칙을 찾아내는 것은 기계가 담당하지만, 이미지데이터=>벡터로 변환할 때 어떠한 특징을 사용할지는 여전히 '사람'이 설계한다. 적합한 특징을 사용하지 않으면 좋은 결과를 얻기 어렵다. 얼굴 인식과 숫자 인식은 다른 특징 추출이 필요할 수 있다.

#### 신경망(딥러닝)의 등장으로 달라진 것
예전에는 **오로지 사람이 생각한 알고리즘**을 토대로 예측하는 방식을 활용했다. 이후 기계학습이 등장하며 **사람이 특징을 생각하고(SIFT, HOG 등) 해당 특징을 토대로 얻은 데이터를 기계학습으로(SVM, KNN 등) 학습**하였다. 하지만 신경망(딥러닝)으로 들어가면 **사람의 개입이 사라진다**.
사람의 개입이 사라진다는게 무슨 말이냐하면, 이미지를 '있는 그대로' 학습하는 것이다. 이미지에 어떠한 특징을 가졌는지 또한 기계가 스스로 학습하는 방법으로 발전되었다.
딥러닝은 종단간 기계학습 (처음부터 끝까지) 라고도 한다. 주어진 데이터를 온전히 학습하고, 문제의 패턴 발견을 시도한다. 주어진 데이터를 그대로 활용하는 end-to-end 학습이 가능해진다.

**훈련데이터, 시험 데이터**
Training Data와 Test data가 있다. 훈련데이터로 학습하며 최적의 파라미터를 찾고, 시험 데이터를 활용하여 훈련한 모델을 평가한다. 왜 나눠야 할까? **범용 능력 평가를 위하여** (훈련에 사용하지도 않은, 아직 보지 못했던 데이터도 잘 해결할 수 있을지)
하나의 데이터셋으로 훈련과 평가를 함께 해버리면 **과적합(OverFitting)** 문제가 발생한다. (이미 학습할 때 본적 있으니 너무 잘 알고있다.) 하나의 데이터셋에만 지나치게 최적화 되면, 다른 데이터셋에 잘 작동하지 않을 것이다.

### 손실함수
신경망 학습의 현재 상태를 **손실함수(Loss Function)** 로 판단한다. 손실함수를 가장 최소로 하게 만드는 가중치 Parameter를 탐색하는 것이 주 목표이다.
손실함수는 일반적으로 **오차제곱합, 교차 엔트로피 오차**를 사용한다. 물론 임의의 함수를 사용할 수도 있다. (손실함수는 성능이 얼마나 '나쁜가'를 판단하는 지표이다. 현재 신경망이 얼마나 잘 처리하지 '못'하냐를 중점으로 본다. 어차피 이걸 토대로 얼마나 좋은지를 알 수 있다. 나쁨을 최소화 하면 좋음이 최대화 된다.)

**오차제곱합** (SSE; sum of squares for erro)
가장 많이 사용되는 손실함수이다. E=1/2 (시그마k)(y_k - t_k)^2
설명하면, y_k는 신경망 출력이다. t_k는 정답 레이블이다. k는 데이터의 차원수이다. 
실제 출력에서 정답을 빼고 제곱처리하면 오차가 나온다. 이렇게 나온 오차들을(오차 ndarray) 모두 더한뒤 2로 나누어 구한다. y와 t는 넘파이 배열이다. 그래서 y-t하고 제곱하면 부호없이 오차들이 넘파이 배열로 반환된다.
실제로 실습해봤을 때, 두번의 y를 넣어봤었다. 손실함수 출력이 더욱 작은 y가 더욱 정답에 가까운 추정 결과라고 할 수 있다.

**교차 엔트로피 오차**
수식은 E = -(시그마k)t_k * ln(y_k) 이다.  y_k는 신경망의 출력, t_k는 정답 레이블. t_k는 정답만 1이고 나머지는 모두 0이다. 따라서 위 식은 실질적인 정답에서의 추정 (t_k)가 1일 때의 -ln(y_k)를 구한것이 된다. (나머지는 다 0으로 나눠져서 사라짐) 만약 정답은 2이고, 그 때 신경망 출력이 0.6이라면 교차 엔트로피는 -log_e(0.6) = 0.51이 된다. 신경망 출력이 0.1이라면 -log_e(0.1) = 2.30 이다. 이처럼 신경망 출력이 높을수록 엔트로피는 최소가 된다.

자연로그는 x가 1일수록 y는 0이되고, x가 0에 가까워질수록 y는 점점 마이너스로 작아진다. 따라서 신경망 출력값이 작아지면 작아질수록 오차는 점점 커질것이다.
실제 실습해보니, 정답일 때의 출력이 클수록 오차가 작고(정답일 가능성 높다) y출력이 작을수록 오차가 크게 나타났다.

### 미니배치 학습
기계학습을 통해 손실함수를 최대한 줄이기위한 parameter를 찾아낸다고했는데, 훈련 데이터에 대한 손실함수 값을 구해야한다. n개의 훈련데이터가 있다면 n개의 손실함수를 얻어내고, 각각 데이터들의 손실함수 값들의 합으로 전체 데이터에 대한 손실율(정답률)을 얻어낸다.

교차 엔트로피 오차인 E = -(시그마k)t_k * ln(y_k) 식에서 모두 더하여 평균을 구하는 식만 추가한다.
E = -**(1/N)(시그마n)**(시그마k)t_nk * ln(y_nk) 
이렇게 평균 손실함수를 구한다면, 훈련 데이터 개수와 관계없이 언제든 통일된 지표를 얻을 수 있다. 데이터가 1000개든.. 10000개든...

MNIST 훈련데이터는 60,000개라는 많은 훈련 데이터를 가지고 있다. 모든 데이터의 손실함수를 구하는 것은 꽤 걸린다. 빅데이터까지 가면 더 어마어마해질 것이다. 그래서 **일일이 모든 손실함수를 구하는 것은 현실적이지 않다**. 일부 데이터를 뽑아 근사치로 이용한다. 일부만 뽑아서 학습을 수행한다. 만약 6만개의 훈련데이터가 있다면, 100장을 무작위로 뽑아서 해당 100장만 학습하는 것이다. => **미니배치 학습**
> 그런데 데이터가 많은 상황에서 일부만 가지고 훈련한다면 데이터의 신뢰도가 그렇게 높지 않을수도 있지 않을까?? 전체 데이터의 개수에서 어느정도의 비율을 뽑아서 사용하는 것이 좋을까? 혹은 일반적으로 어느정도의 비율로 훈련을 진행할까?
> 
> 세상에.. 시청률도 일부 가구 뽑아서 근사하는것이었어???

실습으로 MNIST 데이터를 import하고, np.random.choice(train_size, batch_size)를 통해 무작위로 10개를 빼내어 낼 수 있었다. 여기선 6만개의 데이터에서 10개를 뽑은 것이다. (np.random.choice(60000, 10)) 이렇게 뽑아낸 무작위 index를 통해 미니배치를 뽑아낼 수 있다. 그리고 이러한 미니배치로 손실함수를 계산할 수 있다.

### 손실함수 이유
왜 정확도가 아닌, 손실함수를 사용할까? 궁극적으로 우리가 원하는 것은 정확도인데!
손실함수값을 최대한 적게하는 매개변수를 찾는다고 했다. 이를 찾기 위해 매개변수의 미분(기울기)를 계산하여 그걸 통해서 매개변수를 갱신하기 때문이다.

가중치 매개변수 값의 변화에 손실함수의 변화를 지켜본다. 미분값이 양수면 매개변수를 양의 방향으로 변화시켜서 손실을 줄이고, 미분값이 음수면 매개변수를 음의 방향으로 변화시켜 손실을 줄이고.. 그러다 미분이 0이 되면 더이상 손실함수는 움직이지않은 채, 갱신은 Stop한다.

정확도는 왜 지표가 될 수 없는지? => 미분값이 대부분의 장소에서 0이 된다.
> 왜 정확도는 미분값이 대부분의 장소에서 0이되지? 실제로 어떻게 작동하길래? 바로 아래 이유.

위 질문에 대한 이유를 설명한다. 100장 데이터 중 32장 올바른 인식이 이루어지면 정확도는 32%이다. 만약 정확도가 지표면 가중치를 조금 바꾼다한들 그대로 정확도는 32%일 것이다. 이처럼 매개변수의 약간의 변화로는 정확도가 변경되지 않는다. 개선되어도 32.0123%과 같이 연속적이지않고 33%, 34%같이 귾겨서 변화한다. 
반면 손실함수는 0.92534...처럼 생겼고 매개변수 값의 미세한 변화에 손실함수 값도 0.93432...처럼 연속적으로 변화한다. 

정확도는 어떻게보면 우리가 계단함수를 사용하지 않는것과 비슷한 것이다. 정확도를 하면 대부분의 경우에 기울기(변화율)이 0이고.. 계단함수도 대부분의 장소가 기울기(변화율)가 0이다.
기울기가 0이 되지 않는 덕분에 오히려 신경망이 학습할 수 있는 것이다.

### 수치미분
미분은 한순간의 변화량을 표시한 것. 수식으로는 lim(h->0) f(x+h)-f(x) / h 이다.
미분 계산을 파이썬으로 할 수 있다.
f(x+h)-f(x)의 오차를 줄이기 위해 f(x+h)-f(x-h) / 2로 구하기도 한다. (f(x+h)-f(x)와 f(x)-f(x-h)가 더해진 형태일테니.. /2하면 비슷하지 않을까)
- x+h와 x의 차분은 **전방차분** 이라 하고, x+h와 x-h의 차분은 **중심 차분/중앙 차분** 이라 한다.
```
def numerical_diff(f, x):
	h = 1e04
	return (f(x+h) - f(x-h)) / 2*h
```
이렇게 근사치로 구하는 것이 **수치미분**이다. 우리가 x^2을 미분하여 2x로 구한다는 것은 **해석적 미분**의 해이다. 수치미분은 근사값을 구하는 것이고, 해석적 미분은 오차를 포함하지 않는 진정한 미분값을 구해준다.

f(x)=0.01x^2 + 0.1x라고 하자. 특정 x에서의 미분값을 위 식을 통해 구해보면,
numerical_diff(func, 5) => 0.1999...990898 과 같이 나온다. 이것이 바로 x=5 지점에서 x에 대한 f(x)의 변화량이다. 해석적으로는 df(x)/dx = 0.02x+0.1이고, x=5지점에서 0.2이다. 위에서 근사로 구한 것과 오차가 매우 적으므로 실제로 거의 같은 값이라 생각 가능하다.

#### 편미분
변수가 두개인 상황에서 미분하는 것. f(x0, x1) = x_0^2 + x_1^2 이 있다고 한다.
x0 = 3이고, x1 = 4인 상황에서...
f(x0) = x0^2 + 4^2 / f(x1) = 3^2 + x1^2 이다. 둘을 각각 미분하면 df/dx_0 = 2x_0 이고 df/dx_1 = 2x_1 이다. 따라서 둘은 6과 8이 나온다. 편미분은 즉, 두개의 변수가 있다면 하나의 변수를 기준으로 다른 변수는 상수로 보고(고정된 값) 계산하면 된다.

#### 기울기
x0과 x1의 편미분을 동시에 계산하고 싶다면? x0=3이고 x1=4일 때 (x0, x1) 양쪽의 편미분을 묶어서 (df/dx_0, df/dx_1)을 계산? 모든 변수의 편미분을 벡터로 정리한 것을 Gradient(기울기)라고 함.
원래는 x가 하나의 값이었다면 이제는 ndarray로 이루어진 x도 삽입할 수 있는 것이다. for문으로 배열의 값들을 하나하나 접근하여 기울기를 구하여 해당 index에 넣어주고, 이후 grad를 return하면 모든 데이터들에 대한 기울기가 배열로 담긴 채 return된다.
**기울기가 가리키는 방향은 해당 장소에서 함수 출력값을 가장 크게 줄이는 방향**.

#### 경사 하강법
신경망에서 최적의 매개변수(parameter)를 찾아야 한다. 가중치와 편향. 손실함수가 최솟값이 되는 것이 바로 최적이다. 근데 매개변수 공간이 너무 커서 어디가 최솟값인지 짐작이 잘 안간다.
기울기를 활용한 함수의 최솟값을 찾으려는 것이 바로 경사 하강법이다.

경사하강법은 현재위치에서 기울어진 방향쪽으로 일정거리 이동하고, 거기서 또 기울기 구하고 이동하고, 기울기 구하고 이동하고... 점차 함수의 값이 줄어드는 것을 경사법이라 함.
경사법은 기계학습 최적화에 많이 쓰이고 신경망 학습에 많이 사용한다.

학습률을 미리 정하고 (0.01 혹은 0.001 처럼 ) 반복할 때마다 해당 학습 횟수 갱신하여 진행한다. step인자는 몇번 돌릴것이냐에 대한 정보. 

학습률을 적절히 두는 이유는, 학습률 너무 크면 큰 값으로 발산하기 때문이다. 너무 작으면 갱신안되고 끝.

### 신경망 기울기
가중치 W로 Matrix가 있으면, 해당 가중치 W를 토대로 손실함수의 기울기를 구한다. (dL/dW)의 각 원소는 각각 원소에 대한 편미분이다. 형상은 모두 n * m으로 같다. loss에 따른 가중치의 변화율을 토대로 어느 가중치가 크게 기여하는지 알 수 있고, 손실함수를 줄이기 위해 어느 방향으로 갱신해야하는지 (음의 방향, 양의 방향) 알 수 있다 한다.

### 136페이지까지 완료...