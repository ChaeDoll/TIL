## 발표자 임채윤
### 오차역전파법 구현해보기
앞에서 구현한 계층들을 토대로 조립하여 신경망을 구축할 수 있다.
신경망 학습 전체적인 그림
0) 신경망은 갱신가능한 W(가중치), B(편향)이 있고, 이를 훈련데이터에 적응하도록 조정하는데, 이를 학습이라 한다. 총 네 단계로 진행된다.
1) 미니배치 : 무작위로 일부를 가져와서 미니배치의 손실함수값을 가장 작게하도록 한다
2) 기울기 산출 : 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실함수값을 가장 작게하는 방향을 제시해줄수있다.
3) 매개변수 갱신 : 가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.
4) 반복 (1에서 3을 반복한다)

수치미분을 이용하면 기울기를 산출하기 위해 구현은 쉽지만 계산이 오래 걸렸다. 하지만 오차역전파법을 이용하면 느린 수치미분과는 달리 기울기를 효율적으로 구할 수 있다.

Affine 계층은 그냥 WX+B 를 의미한다. 우리가 N개의 계층으로 구성된 신경망을 이야기 할 때, WX+B와 활성화 함수를 거치는 것을 N번 반복하는 구조를 말한다. (활성화 함수는 ReLU나 Sigmoid를 사용하고 마지막은 SoftmaxWithLoss 같은 계층을 사용함)

오차역전파법을 사용하지 않았을 때와 전체적인 흐름은 비슷하지만, 이전에는 없던 계층 개념을 활용하고, 또한 수치미분이 아닌 오차역전파를 활용한다. 계층마다의 결과값과 오차에 대한 기울기를 구할 수 있다. 

코드로 구현하면 계층을 각각 구현하고 predict 함수에 x값을 입력하여 Layer의 수만큼 layer.forward를 반복하게 한다. 이러면 가장 마지막 활성화함수(Softmax with Loss)를 제외하고 