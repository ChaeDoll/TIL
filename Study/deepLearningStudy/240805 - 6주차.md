## 7장. 합성곱 신경망(CNN)
> CNN이란 (Convolutional Neural Network; 합성곱 신경망)이라고 한다. CNN은 이미지 인식과 음성 인식 등 다양한 곳에서 사용된다.
> 특히 이미지 인식 분야에서 딥러닝 활용 기법은 거의 다 CNN을 기초로 한다.
### 전체 구조
CNN도 신경망을 블록으로 조합했 듯 계층을 조합하여 만들 수 있다.
**합성곱 계층(Convolutional Layer)** 과 **풀링 계층(Pooling Layer)** 이 새롭게 등장한다.
지금까지의 신경망은 인접하는 모든 계층과 연결된 **완전연결 (fully-connected)** 이었고, 이를 Affine계층이라고 구현했다.
Affine-ReLU-Affine-ReLU-Affine-ReLU...-Affine-Softmax  (이런 식으로 진행했었음)

CNN의 구조는 아래와 같다.
Conv-ReLU-Pooling - Conv-ReLU-Pooling - Conv-ReLU - Affine-ReLU-Affine-Softmax (이런 식)

Affine-ReLU의 흐름이 Convolutional-ReLU-Pooling의 조합으로 이어진다고 생각하면 편하다. 그리고 출력에 가까운 계층은 Affine-ReLU를 사용가능하다. 마지막 출력은 Affine-Softmax를 사용하는것이 일반적인 CNN기초다.
### 합성곱 계층 (Convolutional Layer)
CNN은 패딩, 스트라이드와 같은 용어가 등장한다. (padding, stride) 
> [!완전연결 계층의 문제점?]
> 데이터의 형상이 무시된다. 이미지는 가로,세로,색상으로 구성된 3차원 데이터이다. 하지만 완전연결 계층을 위해서 1차원 데이터로 평탄화해야한다. MNIST만 봐도 28x28인데 평탄화하여 784개 특징입력을 했으니말이다.

완전연결 계층은 형상이 주는 정보를 무시하고 모든 입력데이터를 동등한 뉴런으로 취급하기에 형상 정보를 살릴수 없다.

CNN에선 합성곱 계층의 입출력 데이터를 **특징 맵 (feature map)** 이라고도 한다. 합성곱 계층의 입력 데이터를 입력특징 맵, 출력데이터를 출력특징 맵이라고 하는식. 입출력데이터 == 특징 맵
### 합성곱 연산
합성곱 연산은 입력 데이터에 필터를 적용한다. 입력이 4x4이고 필터가 3,3, 출력이 2,2가 된다? 필터를 커널이라 칭하기도 한다.

필터의 윈도우(window)를 일정 간격으로 이동해가며 입력 데이터에 적용한다. 입력과 필터에서 대응하는 원소끼리 곱하고 그 총 합을 구한다. (단일 곱셈-누산; Fused multiply-add; FMA) 이후 그 결과를 출력 해당 장소에 저장한다. 이 과정을 모든 장소에서 수행하면 합성곱연산 출력이 완성된다.

4x4가 있을때 필터가 3x3이다? 그러면 4x4를 3x3으로 나누어보면 네 부분으로 나온다. 
ㅇㅇㅇㅁ    ㅁㅇㅇㅇ    ㅁㅁㅁㅁ    ㅁㅁㅁㅁ         
ㅇㅇㅇㅁ    ㅁㅇㅇㅇ    ㅇㅇㅇㅁ    ㅁㅇㅇㅇ
ㅇㅇㅇㅁ    ㅁㅇㅇㅇ    ㅇㅇㅇㅁ    ㅁㅇㅇㅇ
ㅁㅁㅁㅁ    ㅁㅁㅁㅁ    ㅇㅇㅇㅁ    ㅁㅇㅇㅇ

이렇게 네 부분을 3x3의 필터와 합성곱하게되고, 각 매칭되는 자리끼리 곱한뒤 그 수들을 모두 더해준다. 그리고 네부분으로 2x2의 결과가 나오기에 각 자리에 더했던 수들을 표시해준다.
**CNN도 편향이 존재한다**. 필터를 거친 후 스칼라값 편향을 더하여 출력행렬에 모두 더해줄수있다.
### 패딩
합성곱 연산을 수행하기 전에 주변 데이터를 특정값(예를들면 0)으로 채우기도 한다. 이걸 패딩이라 한다. 4x4인 입력에 3x3의 필터를 끼면 2x2의 결과가 나오는데, 만약 4x4의 입력 가장자리에 패딩값 0을 모두 채우면 6x6의 형상이 될 것이다. 그리하면 3x3 필터를 거쳤을때 결과도 4x4가 된다. 패딩의 두께는 1, 2, 3 등 원하는대로 가능하다.

패딩을 왜하냐? 출력크기를 조정하기 위해서이다. 패딩없이 진행하면 점점 출력크기가 작아지는 문제가 발생한다. 여러 층을 거쳐야하는 신경망 특성상 출력 크기가 1이 되어버리고 말 것이다. 합성곱 연산을 할 수 없는 상황이 될 수 있기에 이 사태를 막기 위해 패딩을 사용한다.
4x4 + 필터3x3인 경우에서 패딩 1을 사용하니 입력도 4x4, 출력도 4x4로 일정한 공간적크기로 다음계층에 전달할 수 있었다.
### 스트라이드
패딩은 입력데이터 가장자리에 패딩값을 넣는 과정이라고 했다. 
스트라이드란 **필터를 적용하는 위치 간격**을 의미한다. 지금까지의 경우가 스트라이드 1일 때이고, 스트라이드가 2라면 필터를 적용하는 윈도우가 2칸씩 이동하게 된다.
스트라이드를 거치면 즉 출력크기가 작아진다. 

패딩과 스트라이드에 따라 출력 크기를 계산해본다면...
$OH=\frac{H+2P-FH}{S}+1$ 이고, $OW=\frac{W+2P-FW}{S}+1$  이다. 입력크기를 (H, W) 라고하고 필터 크기를 (FH, FW), 출력 크기를 (OH, OW), 패딩을 P, 스트라이드를 S라고 한 경우이다.

만약 입력이 4x4이고 패딩이 1, 스트라이드가 1, 필터가 3이다?
OH = (4 + 2 x 1 - 3)/1 + 1 = 4
OW = 4 
따라서 4x4의 출력결과가 나온다.

입력이 7x7이고 패딩은 0, 스트라이드 2, 필터를 3x3이라면?
OH = (7-3)/2+1 = 3
OW = 3
따라서 3x3의 출력이 나온다.

입력이 28x31이고 패딩이 2, 스트라이드 3, 필터가 5x5라면?
OH=(28+2x2-5)/3+1 = 10
OW=(31+2x2-5)/3+1 = 11
따라서 10x11의 출력이 나온다.

이처럼 단순 계산으로 구할 수 있게 된다. 값이 딱 나눠떨어지지 않는 경우 가장 가까운 정수로 반올림하거나 특별히 에러없이 진행하도록 구현하는 경우도 있음.
### 3차원 데이터 합성곱 연산
3차원 합성곱 연산은 2차원에서 채널이 여러개가 된 경우이다. 합성곱 연산을 채널마다 수행하고, 그 결과를 더하여 하나의 출력을 얻는다. 그러니, 만약 4x4x3 이고 필터가 3x3이라면 3개의 층의 4x4를 각각 4x4와 필터 3x3으로 합성곱하고 그 3개의 결과들을 모두 더하여 한 부분의 출력 값으로 한다.
#### 블록으로 생각
3차운 합성곱을 블록으로 생각한다면? 채널, 높이, 너비로 생각하여 (C, H, W)라고 둔다하면... 필터도 (C, FH, FW)이다. 근데 출력은 (1, OH, OW)로 나온다. 어떻게 다수의 채널로 출력시키나?
=> 필터(가중치)를 여러개 사용하는 것.

(C, H, W)와 (FN, C, FH, FW)를 사용하면 (FN, OH, OW)의 결과를 얻을 수 있다. (FN은 필터의 개수)
따라서 필터의 가중치 데이터는 (출력채널수, 입력채널수, 높이, 너비)로 쓴다.
편향의 경우엔? (FN, 1, 1)로 나타낸다. 채널 하나 당 편향 하나로 구성된다.
#### 배치 처리
합성곱 연산도 배치처리를 지원하고자 한다. 각 계층 흐르는 데이터 차원 늘려 4차원 데이터로 저장한다. 데이터를 (데이터 수, 채널 수, 높이, 너비) 순으로 저장. 데이터가 N개일때 배치처리한다면...
(N, C, H, W) (합성곱*) (FN, C, FH, FW) -> (N, FN, OH, OW) + (FN, 1, 1) -> (N, FN, OH, OW)
신경망에 4차원 데이터 하나 흐를때마다 데이터 N개에 대한 합성곱 연산이 이뤄진다는 것.
N회분 처리를 한번에 수행.
### 풀링 계층
풀링이란 세로가로 방향 공간을 줄이는 연산이다. 최대 풀링이라면, 입력값에 스트라이드 값으로 탐색하며 최대값들을 대표로 세워 공간크기를 줄이는 것을 의미한다.
풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통이다.
만약 