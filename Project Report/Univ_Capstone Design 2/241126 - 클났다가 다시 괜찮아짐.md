### 큰일났다.
Segmentation 모델을 적용해봤다.

Object Detection 은 버퍼는 있되, 그래도 동작은 한다였는데
Segmentation은 아예 작동을안하고 메모리부족이 떠버리면서 꺼진다... 
둘다 동시에 키는건 그러면... 불가능....

어라? 코드를 최적화하니까 돌아간다.
기존에는 매 픽셀마다 texture.SetPixel로 정해진 색상을 입력했는데, 이제는 Color 객체에 width * height 만큼의 배열을 만들고 이것을 texture.SetPixel에 배열채로 넣었더니 더이상 메모리로 종료되지 않는다. 
이제 다시 모델 테스트를 한다.
어? outputTensor가 1x8x256x256이 잘 나타난다.

출력되는 1x8x256x256은 batchsize x class x width x height 이다.
따라서 각 채널(클래스) 마다의 width x height픽셀에서의 값 확률값이 나오고, 
즉, 픽셀마다 채널들 중 가장 큰 채널을 가져와서 해당 클래스로 정하고, 해당 클래스에 맞는 색상을 배정한다.
이렇게 배정한 색상을 정면에 보여질 Texture에 반영한다.

둘다 켰다. 된다. 어라? 된다! 오예!
이제 잘 학습된 Semactic Segmentation 모델만 있으면 된다!!!

둘이 동시에 실행하는게 가능하다.

---
다른 테스트 케이스를 위해 **서버로도 열어보려고 한다.**
Unity의 UnityWebRequest 클래스를 활용하고, Flask에서 전송한 이미지 byte[]를 받는다. 
받은 이미지를 서버에서 object detection(yolo), semantic segmentation(deeplab) 적용하여 결과를 json으로 다시 XR Client에게 보낸다.

유니티 Client에서 결과를 활용하는 코드를 작성하여 화면에 띄운다.

StandAlone이랑 ServerProcessing을 Scene을 분리하여 구현한다.