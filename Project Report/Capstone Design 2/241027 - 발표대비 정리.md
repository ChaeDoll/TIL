- 기존에 Unity Lightship ARDK SDK 내부에서 제공하는 Object Detection 기능을 활용하여 장애물 감지를 하려고 하였음.
- 테스트 결과, Object Detection 기능 자체는 잘 작동하지만 **킥보드 또는 자전거**를 잘 분류하지 못하는 문제가 발생하였다.
- 따라서 Object Detection 역시 Image Segmentation과 동일하게 학습된 모델을 ONNX 파일로 변환한 뒤 유니티 Barracuda 딥러닝 프레임워크를 활용하여 실행시키려 한다.
- Object Detection 모델은 **YOLO11n** 모델을 활용하려 한다.
- Python jupyter notebook 환경에서 ultralytics 라는 라이브러리에 포함된 yolo11n 모델을 다운로드 하고, 길거리 사진을 넣어 잘 작동하는지 확인하였다. 
![[result.jpg]]
- 실행 결과, 잘 작동하는 것을 확인할 수 있었고, 해당 모델을 ONNX 파일로 변환하여 유니티에서 활용하고자 하였다. 
- 처음에는 ONNX 파일 변환에 자꾸 실패하여 다양한 시도를 해보았고, ipynb 파일이 아닌 py에서 실행하니 성공적으로 export가 되는 현상을 겪었다.
- 결과적으로 YOLO11n 모델을 ONNX 파일로 변환하였고, 이를 유니티에 Import 해두었다.
- [문제] split 계층에서의 문제 발생으로 인해 Barracuda에서 모델을 import하지 못하였는데, 알고보니 Barracuda는 YOLO 모델의 계층 중에서 split이라는 이름의 계층을 호환하지 않아서 발생하는 문제였다. 따라서 Unity 딥러닝 라이브러리 중, Split 계층을 호환하는 Sentis 라이브러리로 변경하였다.
- 실행 과정은, C# 스크립트를 통해 Model을 로드하고, Worker를 생성한다. 이후 입력 이미지를 가져와 입력 Tensor에 맞게 (1, 3, 640, 640)의 형태로 변경해준다. 이 과정에서 RGB 요소를 하나하나 꺼내거나, 이미지 크기를 Resize 하는 과정이 포함된다.
- Worker를 통해 Model에 입력 데이터를 넣어 결과를 추출하고, 결과 Tensor를 다시 변환하여 사용 가능한 데이터로 활용하고자 한다.
- 현재 이 과정에서 자꾸 코드 문제가 발생하여 해결을 위해 다양한 시도를 하고 있는 상황이다.