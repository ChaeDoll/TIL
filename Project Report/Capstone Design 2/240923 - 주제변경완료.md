
# 이전 주제 결정 및 테스트... 그리고 주제 변경
- AR Campus Navigation이라는 실내.실외 모두 사용 가능한 증강현실(AR) 캠퍼스 내비게이션을 제시하였다.
- AR 캠퍼스 내비게이션의 핵심 기술 중 이런것이 있었다.
	1. 지도 화면을 통해 원하는 출발지부터 도착지까지의 최적의 보행 안내를 증강현실(AR)로 제공
		- 네이버 Map API 또는 Tmap API를 활용하여 제공이 가능. (Static Map, GeoCoding, Routing API)
		- 다만 AR 요소를 위해서는 **Unity를 활용하여 입체적인 Routing Line이 필요**함. 따라서 Static Map은 **REST API(Web기반)의 API들이 아닌**, Unity에 있는 **Mapbox SDK** 또는 **Niantic Lightship Maps SDK**를 활용해야함
		- Mapbox는 기본적으로 요금적인 부분에서 생각보다 과금이 많이 필요하다는것을 알게되었음. 또한 적용하는 과정에서 너무 오래전의 SDK인 탓에 **현재의 Unity AR Foundation 버전과 오류**가 많이 발생
		- Niantic Lightship Maps는 현재 공개가 얼마 되지 않은 Beta 상태이기에 개발 정보 부족과 계속되는 변경사항으로 인해 안정적인 개발이 어려운 상황 (실제로 오류도 많이 발생)
	2. 장소 검색 및 해당 장소 위치를 내비게이션 안내 정보에 활용
		- GeoCoding API 등을 활용하여 원하는 장소의 좌표를 사전에 등록해두어 맵에 마커와 같은 표시로 표현할 수 있으로 구현 가능한 기능으로 판단된다.
	3. 실내 Navigation을 위하여 실제 건물의 3D Mesh가 필요
		- 건물 도면도를 활용해 Blender와 같은 3D Mesh Editor를 활용하여 직접 3D Map을 생성하는 방법이 있음
		- 디자이너가 사용하는 Blender 툴을 활용해서 맵을 생성할 수 있는 인원이 팀에 없었고, 교내의 모든 장소를 직접 하나하나 디자인하는것은 시간이 과다 소요되리라 생각하였음. 
		- 따라서 Camera 기반으로 장소를 Scanning하여 Object Tracking에 활용가능한 방법을 찾기 시작했음
		- 보통 Visual Scanning을 사용하는 방법으로 LiDAR 센서를 활용한다는 것을 파악, 해당 센서 가격을 확
	
	1. 해당 Map을 기반으로 AR Location Tracking을 하여 (VPS; Visual Positioning System) 장소를 파악
	2. 파악한 장소를 기반으로 출발지부터 도착지까지의 내비게이션을 증강현실로 표현
# 새로운 주제
- AR Campus Navigation => Image Segmentation을 활용한 시각 장애인 보행 도우미 앱
- 도보와 도로를 잘 Segmentation하여 나누고, 장애물과 도로로부터 시각장애인이 안전하게 보행할 수 있도록 돕는 앱이다.
- Segmentation 모델을 파인튜닝하여 보행 목적으로 재학습하여 더 정확한 구분이 가능하도록 할 예정이다.
- 또한 도보를 시각장애인들에게 더욱 보기 편한 색상으로 명확하게 구분할 수 있게하여 헷갈림이 없도록 도와줄 예정이다.  (색상을 대입)
#### 설명
- 시각 장애인의 종류는 여러가지가 있음. 대부분의 경우 빛이나 밝은 색상은 어느정도 구분할 수 있음. 점자블록의 색상이 노란색인 것도 그 이유이다.
	- 시각장애인의 90%는 빛을 감지할 수 있다. [뉴스 기사](https://news.kbs.co.kr/news/pc/view/view.do?ncd=5169488) : 온통 노란색이면 보이지않아 헷갈릴수있다? 대비되는 효과를 활용해 길을 구분한다.
- Image Segmentation을 통해 도보와 도로의 경계를 뚜렷한 색상으로 명확하게 나눌 수 있음. 시각장애인이 보행시 이 앱을 통해 걸어도 되는 길인지 아닌지를 확인할 수 있음.
- 또한 Segmentation으로 나눠진 길을 터치하면 음성으로 '도보입니다', '도로입니다.', '장애물입니다' 와 같은 정보를 알려줄 수 있음
- 기존에 Object Detection을 활용해서 시각장애인들에게 위험을 알려주려는 시도는 많이 나타났다. 하지만 그것만으로는 얼마나 가까이. 어디에서 다가오는지 실시간으로 확인하기는 어렵다. Image Segmentation을 활용하면 실시간으로 직접 확인할 수 있기때문에 조금 더 직관적이고 빠르게 대처할 수 있으리라 생각한다.
#### 활용 데이터셋
- 인도 보행영상 이라는 AI허브 데이터셋이 있음. [해당 링크](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=189)
- 1인칭 시점 보행 영상 데이터셋도 있음 [해당 링크](https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=data&dataSetSn=159)
- 해당 데이터셋들을 Segmentation 모델에 활용해서 파인튜닝(학습)하여 활용할 예정이다.
#### 활용 모델
- 현재 3가지 모델을 비교중에 있다
1. OO모델
	- 장점 : 
	- 단점 : 
2. ㅁㅁ모델
	- 장점 : 
	- 단점 :
3. ㅅㅅ모델
	- 장점 :
	- 단점 :
#### 추가 아이디어
- 추가적으로 Segmentation과 **Depth를** 적용한다면, 보행자로부터 가까이에 있는 (세로 중앙 Display에 해당하는 Depth 값 참고) '도로' 또는 '장애물'로 분류되는 경우 **진동 또는 알림**으로 경고를 줄 수 있음
- 도로와 도보에서의 턱을 구분할 수 있으면 좋을 것 같음. (갑자기 낮아지는 경우 위험함)
- 당장은 스마트폰에 적용되는 솔루션이지만, 추후 AR 글래스에 적용된다면 실제로 실시간 보행 보조에 큰 도움을 줄 것 같음