현재 상태를 브리핑해본다.
일단 Image Segmentation과 Object Detection 모두 직접 Unity 라이브러리를 활용하여 Ondevice로 활용할 예정이다. 두 모델 다 받고 (YOLO와 DeepLabv3) Sentis에서 활용한다.

그런데 문제도 있다.
직접 모델을 다운받아 돌리니까 성능때문인지 Delay가 무지막지하게 심하다.
아무래도 스마트폰의 성능의 한계가 있는것같다.

원래 메타 퀘스트도 좋은 퍼포먼스를 보이기 위해 사용하고자 하였으나, 
이미지 활용 (실시간 영상처리)이 막혀있음 (금지되어 있음)
또한 ARDK의 Object Detection같은 경우 스마트폰에서만 작동함. 이러는 문제가 있었다.
하지만 장점으로는 **스마트폰보다 좋은 GPU 성능이 있다는것이다.**

이 말은 즉, 어차피 Segmentation과 Object Detection 모두 직접 돌린다면, 더욱 성능이 좋은 Meta Quest로 돌려도 되지않을까 하는 의문이 드는것이다.
메타 퀘스트로는 실시간 영상 수집이 안되지않냐고??
근데! MediaPipe API? 그것을 활용하면 가능하지 않을까!?
화면에 물체가 보이는 문제가 있으면 어떻게 하냐고?

이것은 어때? 3프레임 중, 1프레임은 감지(이때는 다른 요소들 disable) 2프레임은 감지된 애들 표시 또 1프레임은 감지, 2프레임은 표시... 이런 형태로 
한번 감지하고 그걸 0.1초 보여주고, 다시 한 프레임으로 감지하고 그걸 0.1초동안 보여주고 반복!

좋은 아이디어가 될수도!

--- 
Meta Quest에서 우선 바깥에 움직이며 사용하기 위해서는 Boundaryless가 되어있어야한다.
메타 퀘스트에서는 앱 사용을 위해서는 경계를 설정해야하고, 밖으로 나가면 경계를 재설정하라는 경고창이 뜬다. 그런데 Boundaryless를 적용하면 경계가 사라진다!
https://developers.meta.com/horizon/documentation/unity/unity-boundaryless/
해당 페이지를 참고하여 Boundaryless를 구현하였고, SceneManager과 BoundayManager라는 스크립트를 통해 앱을 시작할 때 Boundary가 꺼지도록 설정하였다.
- [x] 경계 제거 성공

그 다음엔 MediaProjection API를 활용하여 1024x1024의 텍스처를 얻어내야한다.
얻어낸 텍스처를 활용하여 딥러닝의 입력데이터로 입력하면 성공적으로 이를 완수할 수 있다.
https://github.com/trev3d/QuestDisplayAccessDemo/blob/master/Assets/DisplayCapture/DisplayCaptureManager.cs
일단 MediaProjection 가이드를 보면서 따라했다.
그러다가 빌드하려니까 막혔다. 
```
Configuration `releaseRuntimeClasspath` contains AndroidX dependencies, but the `android.useAndroidX` property is not enabled, which may cause runtime issues. See the Console for details.
```
랜다. 그래서 프로젝트 > Library > Bee > Android > Prj > IL2CPP > Gradle > gradle.properties에 들어가서 
`android.useAndroidX = true , android.enableJetifier = true` 이거 두 줄 넣었다. 
자꾸 없어져가지고 custom Gradle Properties 설정 키고 거기 안에 넣으니까 되더라.

이번에는 또다른 문제가 발생했다.
```
A failure occurred while executing com.android.build.gradle.internal.tasks.CheckAarMetadataWorkAction See the Console for details.
```
랜다. 근데 정말 어이없는 이유로 에러 고쳤다. KeyStore Manager 추가하니까 되더라.
추가적으로 Android API버전을 34로 올려야한다. (Android 14.0 / API 34)

빌드에 성공했는데 아무일도 안 일어난다. 텍스트로 디버깅을 해봐도 아무일도 안일어난다.
보니까 자바파일도 가져와야하는듯 하다.

Demo를 참고하여 쓸데없는 요소들을 없애고 필요한 애들만 남겨보았다. 제발 빌드 돼라 ㅠㅠ
빌드가 자꾸 안되길래 찾아보니 Cache때문에 문제가 생길수도 있다고 한다.
C > Users > .gradle > caches를 모두 삭제하고, AppData > LocalLow > Unity 내부 파일 모두 삭제하였다.
그리고 시스템 환경변수도 건드렸다. 

**이것만 가능하면 진짜 큰거 가능한데...**
진짜로!
스마트폰보다 좋다! 할수있는데...

---
Demo가 잘 작동하는 것은 확인했다. (미러링은 불가능하지만 실제로 캡처는 가능했음. 왜냐면 MediaProjection 자체가 Mirroring과 동일한 방식으로 뽑아오는 API이기에 둘이 중첩돼서 안켜짐)

계속되는 빌드 오류에, 그냥 Demo를 Fork하여 가져오고 이를 변형하여 사용하는것이 더욱 빠르겠다고 생각함.

Demo에서 필요없는 QR Reader 기능들은 모두 없애고, Sentis 라이브러리를 설치한뒤 ONNX 모델을 Import하여 실행 가능한지 확인할 예정이다.

