ARDK를 활용해서 깊이센서를 사용해보는것은 어떤지???

#### 랩실분들은 어케하셨을까..
Tensorflow lite로 변환하는 과정에서 ONNX 형태로 변환되나보다. 그렇게 변환시켜서 경량화하는 방법도 사용하셨던것같다.
그런데 onnx 빡세다고 하시네.. 와우..

모바일은 CPU와 GPU사이의 **NPU**로 시스템이 돌아간다고 한다. 이 성능은 CPU와 GPU의 사이쯤이라고 하는데, 추론하는 과정에서 잘 돌아가도록 알맞는 성능의 모델을 선택해야할 것 같다.

### ARDK 사용하면??
- Depth 같은 경우 ARDK가 개선한것이 있다고 들었다.
- ARDK의 Object Detection도 함께 사용한다면 **터치하였을 때** 해당 위치의 장애물이 뭔지 분류해주거나, 아니면 1초마다 장애물 사항을 이야기해거나... 무언가 쓸수있지않을까?
- 또한 Neural Network Model Preloading 이라는것도 알아보자 (가능하면 이걸로 Segmentation 모델 불러오면 되니까) - 그러면 모델을 매번 로드하는것을 방지하는것인가??

- 맥북얻었다! 7895가 비밀번호
### ARDK 세팅
- 기본적인 ARDK 3.0 사전 세팅을 마쳤다. 이후 AR Occlusion Manager 아래에 Lightship Occlusion Extension 컴포넌트를 부착하여 더욱 성능과 사용성이 향상된 Depth를 활용하려 한다.
- Depth Map을 가져오는 코드를 작성하고, Depth Material과 Shader를 생성하여 연결해준뒤 빌드해보았다.
### 실험
- 일단, 이전보다 더욱 가벼워진 느낌이 더욱 들고, 실제로 쓸만한 정도의 이미지가 나타나는것 같다.
- Depth Texture 표시하는 Object를 반투명하게 두어 실제 맵과 겹쳐본다면...
- Shader에 있는 색상값에서 alpha가 1.0f인듯하니, 이걸 0.5로 일단 변경해보았다.