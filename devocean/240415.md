## ▶Web에서 XR(VR,AR) 개발하기

안녕하세요!😊 이번에는 제가 관심을 갖고 있고 개인적으로 공부도 하고 있는 AR(증강현실) 개발에 대해 여러분들께 이야기해드리려 합니다.

목차
- 서론
- 공부 요약
- 실제 WebXR 사용
- 결과 및 정리

### 서론
메타퀘스트3, 애플비전프로와 같은 기기들로 현재 XR(혼합현실)이 서서히 우리에게 다가오고 있는데요, 사실 VR은 우리의 일상생활에 흔하게 적용된 예시는 잘 없지만 AR(증강현실)에 경우에는 의외로 우리 근처에서 사용되는 예시가 많습니다!  
증강현실의 예시로 다들 '포켓몬GO'를 많이 이야기 하지만 사실 그것 외에도 얼굴 필터 카메라 어플인 Snow, 인스타그램 필터와 같은 얼굴 인식 필터 기술들도 전부 AR의 예시라고 볼 수 있습니다. 이러한 APP들을 시작으로 Jump, AR이모지 등 여러 앱들이 등장하고 있는 추세입니다.  

AR 혹은 VR에 관심을 갖고 개발을 하는 경우에, 다들 ARCore(Android), ARKit(iOS), UnityARFoundation(통합플랫폼)과 같은 소프트웨어를 통해 개발을 접하곤 합니다.   저의 경우에도 처음에는 Unity AR Foundation을 활용해서 특정 사진을 보여주면 영상을 띄워주는 간단한 apk를 만드는 것부터 개발을 접해보았던 기억이 나네요!

이 외에도 WebXR이라는 api를 통해 개발하면, 별도의 프로그램 다운로드 없이 웹에서도 XR 컨텐츠를 즐길 수 있다는 말은 들어보았으나, 정보가 아직 널리 없고 브라우저 호환성이 낮아 컨텐츠 사용에 많은 제한이 있다는 것을 알고 관심을 나중으로 미루어 놓았었습니다.

하지만 최근 WebXR의 근황에 대해 찾아보던 중, Apple이 비전프로와 함께 머지 않아 WebXR api를 지원한다는 발표를 통해 iOS 브라우저에도 호환이 될 예정이라는 정보를 알게되었습니다. 이후 추가적으로 WebXR 공식문서를 통해 ReactXR 이라는 라이브러리를 통해 React 환경에서도 XR개발을 할 수 있다는 것을 알게 되었습니다. (아직 아쉬운 점이 많아요)

아래 링크는 XR기기 혹은 스마트폰(Android) 환경에서 실제로 동작하는 WebXR 샘플 코드들입니다.  
➡️https://immersive-web.github.io/webxr-samples/  

두 번째 사진을 보시면, 실제 제 스마트폰(Android) 환경에서 브라우저를 통해 AR HitTest 샘플을 실행시킨 예시입니다. 이처럼 웹 환경에서도 이제 AR 혹은 VR을 접할 수 있습니다.

저도 이러한 샘플들과 공식문서를 토대로 공부하고 코드를 넣어보며 간단한 웹사이트를 만들어보았는데요, 이 과정에서 공부한 내용을 간단히 요약하며 React를 통해 WebXR을 사용하는 예시를 여러분들께 공유하려고 합니다.

### 공부 요약
먼저, WebXR은 Three.js라는 라이브러리를 기반으로 만들어졌는데요, 저는 우선 Three.js에 대해서 알 필요가 있었습니다. Three.js를 간단하게 설명하자면 '웹 브라우저에서 3차원 컴퓨터 그래픽스 애니메이션 응용을 만들고 표현하기 위해 사용되는 자바스크립트 라이브러리이자 API' 라고 할 수 있습니다.  
Three.js가 3D Object를 웹 브라우저에 띄우기 위해서는 크게 5가지 요소가 필요했습니다.
1) Scene(물체를 띄울 공간)
2) 그 위에 올려놓을 Mesh(물체)라는 3D Object
3) 물체를 비춰줄 Light
4) Camera(사용자 시점)의 위치
5) Renderer(위와 같은 정보들을 담은 Scene을 출력)

이러한 내용들은 추후 AR, XR을 개발할 때의 기초지식이기에 중요한 내용이었습니다.  
Three.js에 대한 기초지식을 쌓은 뒤에는 React 환경에서 Three.js를 사용하는 R3F(React Three Fiber)에 대해 간단히 학습했습니다.  
Three.js에 대한 코드를 React에서 컴포넌트화하여 사용자가 더욱 쉽게 3D Object에 접근할 수 있도록 해주었습니다.

실제로 Three.js와 R3F를 통해 코드를 작성하면 차이가 많이 드러납니다. 간단한 큐브를 만드는 과정을 두 코드 예시와 함께 비교해보겠습니다.
```
/* Three.js 코드 예시 */

// Scene 생성
const scene = new THREE.Scene();

// Camera를 생성 후 fov, aspect, near, far 설정
const camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 );

// Renderer를 생성
const renderer = new THREE.WebGLRenderer();
renderer.setSize( window.innerWidth, window.innerHeight );

// Renderer를 DOM에 추가
document.body.appendChild( renderer.domElement );

// Cube Mesh를 만들어서 Scene에 추가
const geometry = new THREE.BoxGeometry( 1, 1, 1 ); // widht, height, depth
const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );
// Mesh는 Geometry와 Material이 필요합니다.
const cube = new THREE.Mesh( geometry, material );
scene.add( cube );
camera.position.z = 5;

// requestAnimationFrame 메소드를 통해 Renderer를 계속 Rendering 해준다.
function animate() {
	requestAnimationFrame( animate );
	renderer.render( scene, camera );
}
animate();
```
```
/* R3F 코드 예시 */
function 3DView(){
        return (
                <Canvas camera={{position:[0,0,-5]}}> // Scene 역할
                        <ambientLight/> // Light 설정
                        <mesh>  // Mesh 설정
                                <boxGeometry args={[1,1,1]}>
                                <meshStandardMaterial color={"0x00ff00"} />
                        </mesh>
                </Canvas>
        )
}
```
똑같은 결과를 반환하는 코드지만 조금 더 재사용성이 높고 직관적인 것은 R3F 코드같다고 생각했습니다.

이처럼 Three.js, R3F에 대해 학습한 이후엔 본격적으로 간단한 테스트 웹사이트를 만들기 시작했습니다.

### 실제 WebXR 사용
웹에서 XR(AR, VR)을 개발 하고 해당 기능을 테스트 해야했는데, PC 환경에서는 VR 혹은 AR을 실행시킬 도구가 존재하지 않았습니다. 따라서 Chrome에 있는 WebXR API Emulator 라는 확장프로그램을 설치하여 마치 스마트폰 혹은 XR기기에서 웹에 접속하는 듯한 환경을 제공해주었습니다.

처음엔 React Project에서 @react-three/xr 라이브러리를 추가하고, 기본적인 구성과 함께 코드를 작성해보았습니다.  
```
function App() {
  return (
    <>
      <ARButton sessionInit={{
      optionalFeatures:["hit-test"]
      }}>
        <Canvas>
          <XR>
            <ambientLight />
            <pointLight position={[5, 5, 5]} />
            <Controllers />
            <ARTestContainer />
          </XR>
        </Canvas>
      </ARButton>
    </>
  )
}
export default App;
```
저는 AR을 테스트 해봤습니다. 이렇게 ReactXR을 활용하여 ARButton을 통해 AR모드로 XR 세션에 접근하여 바닥면에 화면 중앙을 따라 움직이는 링을 터치 시 Cube가 생성되는 ARTestContainer를 구성했습니다.

세 번째 사진을 보면, 웹으로 프로젝트를 실행했을 때의 화면을 보여줍니다. 하나의 Room이 등장하고 가운데에 거울처럼 보이는 것이 바로 AR 기능을 보기 위한 스마트폰이고, 화면을 터치하면 링이 있는 위치에 파란 큐브가 생성됩니다.
이를 Netlify를 통해 배포하고, 스마트폰을 통해 확인해 보면 네 번째 사진과 같이 AR 모드로 진입하는 버튼과 함께 Object를 미리보기 하는 페이지가 완성됩니다.  

하지만 이상하게 컴퓨터에서는 잘 작동하던 ReactXR AR기능이 스마트폰에 가면 카메라가 켜지지 않아 적용이 안되는 안타까운 오류를 마주했습니다.  
ReactXR의 경우 사용자 라이브러리이기도 하고, 2023년 9월에 마지막으로 업데이트 된 점을 보아 적용이 안되는 것은 어쩌면 당연할 수도 있겠다 싶었습니다.  
ARButton 대신, VRButton을 통해 VR모드로 전환해보니, 이제는 스마트폰에서도 잘 작동하는 것을 볼 수 있었습니다.

아래 링크는 Netlify에 배포한 페이지입니다. (컴퓨터에서 실행하기 위해선 WebXR API Emulator 확장프로그램을 설치해야함)
➡️https://chaeyunr3fpractice.netlify.app


### 결과 및 정리
너무하다 싶을 정도로 정보가 없기에 스스로 탐구하고 뜯어보며 기능을 테스트 해보았는데요, 그 과정에서 좌절스러움도 겪었지만..(또르르) 그래도 도전해봤기에 이러한 경험을 쌓을 수 있었다고 생각합니다. 

VR(가상현실)을 개발한다면, 오늘 알아본 ReactXR을 통해 충분히 구현이 가능해보였습니다. 하지만 AR(증강현실)의 경우는 ReactXR 라이브러리의 문제 탓인지 당장은 스마트폰을 통해 기능을 테스트하기 어려워보였습니다.  
AR 프로젝트를 만들어보기 위해서는 R3F(React Three Fiber)와 WebXR API 공식문서를 이용한 다른 방법을 찾아봐야겠다고 결론을 내리게 되었습니다! 꾸준히 WebXR 코드를 공부하고 사용해보며 이후에는 원하는 AR, VR Project를 자유자재로 Web으로 구현해 볼 수 있다면 정말 좋겠네요ㅎㅎ